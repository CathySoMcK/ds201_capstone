{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "from pandas.core import datetools\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import recall_score, average_precision_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset from Excel file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the files produced in the previous Python notebook that performed cleansing and initial feature reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_unscaled = pd.read_csv('data/HID_features.csv', index_col=0)\n",
    "df_clean = pd.read_csv('data/df_clean.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4846, 36)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_unscaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Auto_Ship_Ind', 'Interior_Decor_Signage_Available_Funds',\n",
       "       'LMS_Enrolled', 'LMS_Available_Matching_Funds',\n",
       "       'LMS_Used_Funds_Most_Recent_3_Months',\n",
       "       'LMS_Used_Funds_Previous_3_Months', 'Open_Smart', 'PIP_Program',\n",
       "       'PQS_Program', 'SCS_Program', 'Spar_Coverage_Ind',\n",
       "       'Specialty_Solutions', 'Vaccine_Items', 'Vaccine_Starter',\n",
       "       'Vaccine_Items_Count', 'Vaccine_Items_Sls_Amt', 'YPO', 'Tot_Sls_Amt',\n",
       "       'DLC_Program_encoded', 'FEM_Program_encoded',\n",
       "       'HM_Circular_Program_encoded', 'Internal_Decor', 'PQS_Enrolled_encoded',\n",
       "       'ST_encoded', 'Pog_Code_Name_encoded', 'DC_Name_encoded',\n",
       "       'Bus_Type_Desc_encoded', 'Region_encoded', 'PSAO_Expanded_encoded',\n",
       "       'Chain_Name_encoded', 'Salesperson_encoded', 'AH_Program_encoded',\n",
       "       'OTC_Front-end_Size_encoded', 'MRA_Program_Type_-_Active_AH_encoded',\n",
       "       'Msa_Dma_encoded', 'Signage_Program_encoded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_unscaled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Auto_Ship_Ind</th>\n",
       "      <th>Interior_Decor_Signage_Available_Funds</th>\n",
       "      <th>LMS_Enrolled</th>\n",
       "      <th>LMS_Available_Matching_Funds</th>\n",
       "      <th>LMS_Used_Funds_Most_Recent_3_Months</th>\n",
       "      <th>LMS_Used_Funds_Previous_3_Months</th>\n",
       "      <th>Open_Smart</th>\n",
       "      <th>PIP_Program</th>\n",
       "      <th>PQS_Program</th>\n",
       "      <th>SCS_Program</th>\n",
       "      <th>...</th>\n",
       "      <th>Bus_Type_Desc_encoded</th>\n",
       "      <th>Region_encoded</th>\n",
       "      <th>PSAO_Expanded_encoded</th>\n",
       "      <th>Chain_Name_encoded</th>\n",
       "      <th>Salesperson_encoded</th>\n",
       "      <th>AH_Program_encoded</th>\n",
       "      <th>OTC_Front-end_Size_encoded</th>\n",
       "      <th>MRA_Program_Type_-_Active_AH_encoded</th>\n",
       "      <th>Msa_Dma_encoded</th>\n",
       "      <th>Signage_Program_encoded</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Account</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10491</th>\n",
       "      <td>1</td>\n",
       "      <td>1724.0</td>\n",
       "      <td>1</td>\n",
       "      <td>822.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17475</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19901</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309745</th>\n",
       "      <td>0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652229</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>340.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Auto_Ship_Ind  Interior_Decor_Signage_Available_Funds  LMS_Enrolled  \\\n",
       "Account                                                                        \n",
       "10491                1                                  1724.0             1   \n",
       "17475                1                                     0.0             1   \n",
       "19901                0                                     0.0             1   \n",
       "309745               0                                  2500.0             1   \n",
       "652229               0                                     0.0             1   \n",
       "\n",
       "         LMS_Available_Matching_Funds  LMS_Used_Funds_Most_Recent_3_Months  \\\n",
       "Account                                                                      \n",
       "10491                           822.0                                    1   \n",
       "17475                             0.0                                    1   \n",
       "19901                             0.0                                    1   \n",
       "309745                            0.0                                    0   \n",
       "652229                          340.0                                    1   \n",
       "\n",
       "         LMS_Used_Funds_Previous_3_Months  Open_Smart  PIP_Program  \\\n",
       "Account                                                              \n",
       "10491                                   1           0            1   \n",
       "17475                                   1           0            0   \n",
       "19901                                   1           0            1   \n",
       "309745                                  0           0            0   \n",
       "652229                                  0           0            0   \n",
       "\n",
       "         PQS_Program  SCS_Program           ...             \\\n",
       "Account                                     ...              \n",
       "10491              1            1           ...              \n",
       "17475              1            1           ...              \n",
       "19901              1            1           ...              \n",
       "309745             0            0           ...              \n",
       "652229             1            0           ...              \n",
       "\n",
       "         Bus_Type_Desc_encoded  Region_encoded  PSAO_Expanded_encoded  \\\n",
       "Account                                                                 \n",
       "10491                        0               3                     16   \n",
       "17475                        0               3                      0   \n",
       "19901                        0               3                      0   \n",
       "309745                       0               3                      0   \n",
       "652229                       0               3                      0   \n",
       "\n",
       "         Chain_Name_encoded  Salesperson_encoded  AH_Program_encoded  \\\n",
       "Account                                                                \n",
       "10491                    39                    1                   4   \n",
       "17475                    39                    1                   0   \n",
       "19901                    39                    1                   0   \n",
       "309745                   39                    1                   0   \n",
       "652229                   38                    1                   0   \n",
       "\n",
       "         OTC_Front-end_Size_encoded  MRA_Program_Type_-_Active_AH_encoded  \\\n",
       "Account                                                                     \n",
       "10491                             1                                     7   \n",
       "17475                             3                                     3   \n",
       "19901                             4                                     2   \n",
       "309745                            1                                     8   \n",
       "652229                            0                                     8   \n",
       "\n",
       "         Msa_Dma_encoded  Signage_Program_encoded  \n",
       "Account                                            \n",
       "10491                183                        0  \n",
       "17475                190                        0  \n",
       "19901                183                        0  \n",
       "309745               183                        3  \n",
       "652229               183                        0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_unscaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df_clean['340B_Active']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_unscaled)\n",
    "scaled_features = scaler.transform(X_unscaled)\n",
    "X = pd.DataFrame(scaled_features,columns=X_unscaled.columns, index=X_unscaled.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X['Brand_Rx_Sls_Amt'] = df_clean['Brand_Rx_Sls_Amt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X['Gnrc_Rx_Sls_Amt'] = df_clean['Gnrc_Rx_Sls_Amt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Os_Gnrc_Rx_Sls_Amt'] = df_clean['Os_Gnrc_Rx_Sls_Amt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X['Otc_Sls_Amt'] = df_clean['Otc_Sls_Amt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Brand_pct'] = X['Brand_Rx_Sls_Amt']/X['Tot_Sls_Amt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Generic_pct'] = (X['Gnrc_Rx_Sls_Amt']+X['Os_Gnrc_Rx_Sls_Amt'])/X['Tot_Sls_Amt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X['Otc_pct'] = X['Otc_Sls_Amt']/X['Tot_Sls_Amt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop('Brand_Rx_Sls_Amt', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.drop('Gnrc_Rx_Sls_Amt', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.drop('Os_Gnrc_Rx_Sls_Amt', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop('Otc_Sls_Amt', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4846, 39)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Auto_Ship_Ind</th>\n",
       "      <th>Interior_Decor_Signage_Available_Funds</th>\n",
       "      <th>LMS_Enrolled</th>\n",
       "      <th>LMS_Available_Matching_Funds</th>\n",
       "      <th>LMS_Used_Funds_Most_Recent_3_Months</th>\n",
       "      <th>LMS_Used_Funds_Previous_3_Months</th>\n",
       "      <th>Open_Smart</th>\n",
       "      <th>PIP_Program</th>\n",
       "      <th>PQS_Program</th>\n",
       "      <th>SCS_Program</th>\n",
       "      <th>...</th>\n",
       "      <th>Chain_Name_encoded</th>\n",
       "      <th>Salesperson_encoded</th>\n",
       "      <th>AH_Program_encoded</th>\n",
       "      <th>OTC_Front-end_Size_encoded</th>\n",
       "      <th>MRA_Program_Type_-_Active_AH_encoded</th>\n",
       "      <th>Msa_Dma_encoded</th>\n",
       "      <th>Signage_Program_encoded</th>\n",
       "      <th>Brand_pct</th>\n",
       "      <th>Generic_pct</th>\n",
       "      <th>Otc_pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Account</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10491</th>\n",
       "      <td>1.266482</td>\n",
       "      <td>0.378602</td>\n",
       "      <td>0.471375</td>\n",
       "      <td>-0.227769</td>\n",
       "      <td>1.417723</td>\n",
       "      <td>1.438413</td>\n",
       "      <td>-0.29872</td>\n",
       "      <td>1.557934</td>\n",
       "      <td>0.578780</td>\n",
       "      <td>0.871930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974998</td>\n",
       "      <td>-1.695111</td>\n",
       "      <td>2.785719</td>\n",
       "      <td>-0.900617</td>\n",
       "      <td>0.488720</td>\n",
       "      <td>1.538394</td>\n",
       "      <td>-1.191011</td>\n",
       "      <td>-4.836143e+05</td>\n",
       "      <td>-1.683480e+05</td>\n",
       "      <td>-27963.371044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17475</th>\n",
       "      <td>1.266482</td>\n",
       "      <td>-1.245755</td>\n",
       "      <td>0.471375</td>\n",
       "      <td>-0.599414</td>\n",
       "      <td>1.417723</td>\n",
       "      <td>1.438413</td>\n",
       "      <td>-0.29872</td>\n",
       "      <td>-0.641876</td>\n",
       "      <td>0.578780</td>\n",
       "      <td>0.871930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974998</td>\n",
       "      <td>-1.695111</td>\n",
       "      <td>-0.456453</td>\n",
       "      <td>0.065811</td>\n",
       "      <td>-1.154818</td>\n",
       "      <td>1.650666</td>\n",
       "      <td>-1.191011</td>\n",
       "      <td>2.864914e+06</td>\n",
       "      <td>1.121222e+06</td>\n",
       "      <td>425435.811787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19901</th>\n",
       "      <td>-0.789589</td>\n",
       "      <td>-1.245755</td>\n",
       "      <td>0.471375</td>\n",
       "      <td>-0.599414</td>\n",
       "      <td>1.417723</td>\n",
       "      <td>1.438413</td>\n",
       "      <td>-0.29872</td>\n",
       "      <td>1.557934</td>\n",
       "      <td>0.578780</td>\n",
       "      <td>0.871930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974998</td>\n",
       "      <td>-1.695111</td>\n",
       "      <td>-0.456453</td>\n",
       "      <td>0.549025</td>\n",
       "      <td>-1.565702</td>\n",
       "      <td>1.538394</td>\n",
       "      <td>-1.191011</td>\n",
       "      <td>-5.845785e+05</td>\n",
       "      <td>-2.620634e+05</td>\n",
       "      <td>-40746.406105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309745</th>\n",
       "      <td>-0.789589</td>\n",
       "      <td>1.109752</td>\n",
       "      <td>0.471375</td>\n",
       "      <td>-0.599414</td>\n",
       "      <td>-0.705357</td>\n",
       "      <td>-0.695211</td>\n",
       "      <td>-0.29872</td>\n",
       "      <td>-0.641876</td>\n",
       "      <td>-1.727772</td>\n",
       "      <td>-1.146881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974998</td>\n",
       "      <td>-1.695111</td>\n",
       "      <td>-0.456453</td>\n",
       "      <td>-0.900617</td>\n",
       "      <td>0.899605</td>\n",
       "      <td>1.538394</td>\n",
       "      <td>1.533602</td>\n",
       "      <td>-9.070088e+05</td>\n",
       "      <td>-3.736435e+05</td>\n",
       "      <td>-89951.839100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652229</th>\n",
       "      <td>-0.789589</td>\n",
       "      <td>-1.245755</td>\n",
       "      <td>0.471375</td>\n",
       "      <td>-0.445692</td>\n",
       "      <td>1.417723</td>\n",
       "      <td>-0.695211</td>\n",
       "      <td>-0.29872</td>\n",
       "      <td>-0.641876</td>\n",
       "      <td>0.578780</td>\n",
       "      <td>-1.146881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.913989</td>\n",
       "      <td>-1.695111</td>\n",
       "      <td>-0.456453</td>\n",
       "      <td>-1.383831</td>\n",
       "      <td>0.899605</td>\n",
       "      <td>1.538394</td>\n",
       "      <td>-1.191011</td>\n",
       "      <td>-4.225793e+05</td>\n",
       "      <td>-7.582184e+04</td>\n",
       "      <td>-13778.939499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Auto_Ship_Ind  Interior_Decor_Signage_Available_Funds  LMS_Enrolled  \\\n",
       "Account                                                                        \n",
       "10491         1.266482                                0.378602      0.471375   \n",
       "17475         1.266482                               -1.245755      0.471375   \n",
       "19901        -0.789589                               -1.245755      0.471375   \n",
       "309745       -0.789589                                1.109752      0.471375   \n",
       "652229       -0.789589                               -1.245755      0.471375   \n",
       "\n",
       "         LMS_Available_Matching_Funds  LMS_Used_Funds_Most_Recent_3_Months  \\\n",
       "Account                                                                      \n",
       "10491                       -0.227769                             1.417723   \n",
       "17475                       -0.599414                             1.417723   \n",
       "19901                       -0.599414                             1.417723   \n",
       "309745                      -0.599414                            -0.705357   \n",
       "652229                      -0.445692                             1.417723   \n",
       "\n",
       "         LMS_Used_Funds_Previous_3_Months  Open_Smart  PIP_Program  \\\n",
       "Account                                                              \n",
       "10491                            1.438413    -0.29872     1.557934   \n",
       "17475                            1.438413    -0.29872    -0.641876   \n",
       "19901                            1.438413    -0.29872     1.557934   \n",
       "309745                          -0.695211    -0.29872    -0.641876   \n",
       "652229                          -0.695211    -0.29872    -0.641876   \n",
       "\n",
       "         PQS_Program  SCS_Program      ...        Chain_Name_encoded  \\\n",
       "Account                                ...                             \n",
       "10491       0.578780     0.871930      ...                  0.974998   \n",
       "17475       0.578780     0.871930      ...                  0.974998   \n",
       "19901       0.578780     0.871930      ...                  0.974998   \n",
       "309745     -1.727772    -1.146881      ...                  0.974998   \n",
       "652229      0.578780    -1.146881      ...                  0.913989   \n",
       "\n",
       "         Salesperson_encoded  AH_Program_encoded  OTC_Front-end_Size_encoded  \\\n",
       "Account                                                                        \n",
       "10491              -1.695111            2.785719                   -0.900617   \n",
       "17475              -1.695111           -0.456453                    0.065811   \n",
       "19901              -1.695111           -0.456453                    0.549025   \n",
       "309745             -1.695111           -0.456453                   -0.900617   \n",
       "652229             -1.695111           -0.456453                   -1.383831   \n",
       "\n",
       "         MRA_Program_Type_-_Active_AH_encoded  Msa_Dma_encoded  \\\n",
       "Account                                                          \n",
       "10491                                0.488720         1.538394   \n",
       "17475                               -1.154818         1.650666   \n",
       "19901                               -1.565702         1.538394   \n",
       "309745                               0.899605         1.538394   \n",
       "652229                               0.899605         1.538394   \n",
       "\n",
       "         Signage_Program_encoded     Brand_pct   Generic_pct        Otc_pct  \n",
       "Account                                                                      \n",
       "10491                  -1.191011 -4.836143e+05 -1.683480e+05  -27963.371044  \n",
       "17475                  -1.191011  2.864914e+06  1.121222e+06  425435.811787  \n",
       "19901                  -1.191011 -5.845785e+05 -2.620634e+05  -40746.406105  \n",
       "309745                  1.533602 -9.070088e+05 -3.736435e+05  -89951.839100  \n",
       "652229                 -1.191011 -4.225793e+05 -7.582184e+04  -13778.939499  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try some models and look at performance metrics and important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into train-test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score cross-validated:  0.826248978266\n",
      "Recall Score:  0.111111111111\n",
      "Precision Score average:   0.21438697318\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "rf.feature_importances_\n",
    "pred_rf = rf.predict(X_test) \n",
    "rf_score_acc = np.mean(cross_val_score(rf, X_train, y_train, cv=5))\n",
    "rf_score_recall = recall_score(y_test, pred_rf)\n",
    "rf_score_avgprecision = average_precision_score(y_test, pred_rf)\n",
    "\n",
    "print(\"Accuracy Score cross-validated: \", rf_score_acc)\n",
    "print(\"Recall Score: \", rf_score_recall)\n",
    "print(\"Precision Score average:  \", rf_score_avgprecision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important measure for this business problem is Recall.  This is because Recall captures how many actual Positives the model finds.  In other words, does the model correctly predict current contract pharmacies of Macro Helix?   We want a model that can recognize an actual contract pharmacy.  Precision is not as important, as this captures how many the model labels as positive, compared to how many of those actually are positive; since we know that most of the pharmacies are not currently contract pharmacies, this measure is not very useful to the problem.  Similarly, Accuracy/R2 is not as important because since most in the dataset are negative, the model could merely predict all are negative and have a great Accuracy/R2 score -- not very meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score cross-validated:  0.754768977622\n",
      "Recall Score:  0.379928315412\n",
      "Precision Score average:   0.228701052197\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "dt.feature_importances_\n",
    "pred_dt = dt.predict(X_test) \n",
    "dt_score_acc = np.mean(cross_val_score(dt, X_train, y_train, cv=5))\n",
    "dt_score_recall = recall_score(y_test, pred_dt)\n",
    "dt_score_avgprecision = average_precision_score(y_test, pred_dt)\n",
    "\n",
    "print(\"Accuracy Score cross-validated: \", dt_score_acc)\n",
    "print(\"Recall Score: \", dt_score_recall)\n",
    "print(\"Precision Score average:  \", dt_score_avgprecision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Feature Importance\n",
      "Auto_Ship_Ind                                     0.014865\n",
      "Interior_Decor_Signage_Available_Funds            0.038878\n",
      "LMS_Enrolled                                      0.008608\n",
      "LMS_Available_Matching_Funds                      0.056130\n",
      "LMS_Used_Funds_Most_Recent_3_Months               0.013339\n",
      "LMS_Used_Funds_Previous_3_Months                  0.006634\n",
      "Open_Smart                                        0.005416\n",
      "PIP_Program                                       0.007437\n",
      "PQS_Program                                       0.001004\n",
      "SCS_Program                                       0.000000\n",
      "Spar_Coverage_Ind                                 0.007421\n",
      "Specialty_Solutions                               0.001076\n",
      "Vaccine_Items                                     0.006167\n",
      "Vaccine_Starter                                   0.007821\n",
      "Vaccine_Items_Count                               0.016945\n",
      "Vaccine_Items_Sls_Amt                             0.032776\n",
      "YPO                                               0.007397\n",
      "Tot_Sls_Amt                                       0.086442\n",
      "DLC_Program_encoded                               0.022300\n",
      "FEM_Program_encoded                               0.019194\n",
      "HM_Circular_Program_encoded                       0.005910\n",
      "Internal_Decor                                    0.006938\n",
      "PQS_Enrolled_encoded                              0.005131\n",
      "ST_encoded                                        0.045369\n",
      "Pog_Code_Name_encoded                             0.021329\n",
      "DC_Name_encoded                                   0.037606\n",
      "Bus_Type_Desc_encoded                             0.014856\n",
      "Region_encoded                                    0.008837\n",
      "PSAO_Expanded_encoded                             0.008760\n",
      "Chain_Name_encoded                                0.057231\n",
      "Salesperson_encoded                               0.066442\n",
      "AH_Program_encoded                                0.006245\n",
      "OTC_Front-end_Size_encoded                        0.039503\n",
      "MRA_Program_Type_-_Active_AH_encoded              0.031005\n",
      "Msa_Dma_encoded                                   0.087843\n",
      "Signage_Program_encoded                           0.010370\n",
      "Brand_pct                                         0.061709\n",
      "Generic_pct                                       0.060511\n",
      "Otc_pct                                           0.064554\n"
     ]
    }
   ],
   "source": [
    "feature_imp_dt = pd.DataFrame({'Feature Importance' : dt.feature_importances_}, index=X.columns)\n",
    "print(feature_imp_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score cross-validated:  0.831794072845\n",
      "Recall Score:  0.154121863799\n",
      "Precision Score average:   0.234700528202\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train, y_train)\n",
    "gb.feature_importances_\n",
    "pred_gb = gb.predict(X_test) \n",
    "gb_score_acc = np.mean(cross_val_score(gb, X_train, y_train, cv=5))\n",
    "gb_score_recall = recall_score(y_test, pred_gb)\n",
    "gb_score_avgprecision = average_precision_score(y_test, pred_gb)\n",
    "\n",
    "print(\"Accuracy Score cross-validated: \", gb_score_acc)\n",
    "print(\"Recall Score: \", gb_score_recall)\n",
    "print(\"Precision Score average:  \", gb_score_avgprecision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show which features are most important\n",
    "\n",
    "def plot_feature_importance(model, df):\n",
    "    cols = []\n",
    "    for col in df.columns:\n",
    "        cols.append(col)\n",
    "\n",
    "    feature_importances = pd.DataFrame({'Feature Importance' : model.feature_importances_}, index=cols)\n",
    "    feature_importances = feature_importances.sort_values(by='Feature Importance')\n",
    "    feature_importances.plot(kind='barh', color='r', figsize=(6,6))\n",
    "    plt.title('Feature Importance', fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figures/feat_import.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAGoCAYAAAATsnHAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYRiGkZJYA2UYhmGkJP8PUazCdBu3qcMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd113080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_feature_importance(dt, X_test)              ### drop in the model with best recall here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.665048\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>340B_Active</td>   <th>  No. Observations:  </th>  <td>  4846</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  4807</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>    38</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Thu, 29 Mar 2018</td> <th>  Pseudo R-squ.:     </th>  <td>-0.4412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>11:49:38</td>     <th>  Log-Likelihood:    </th> <td> -3222.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -2236.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>  <td> 1.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                     <td></td>                       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Auto_Ship_Ind</th>                          <td>    0.0940</td> <td>    0.033</td> <td>    2.828</td> <td> 0.005</td> <td>    0.029</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Interior_Decor_Signage_Available_Funds</th> <td>    0.0132</td> <td>    0.041</td> <td>    0.325</td> <td> 0.745</td> <td>   -0.067</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LMS_Enrolled</th>                           <td>    0.0182</td> <td>    0.035</td> <td>    0.520</td> <td> 0.603</td> <td>   -0.050</td> <td>    0.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LMS_Available_Matching_Funds</th>           <td>    0.1136</td> <td>    0.035</td> <td>    3.265</td> <td> 0.001</td> <td>    0.045</td> <td>    0.182</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LMS_Used_Funds_Most_Recent_3_Months</th>    <td>    0.0288</td> <td>    0.044</td> <td>    0.648</td> <td> 0.517</td> <td>   -0.058</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LMS_Used_Funds_Previous_3_Months</th>       <td>   -0.0104</td> <td>    0.044</td> <td>   -0.234</td> <td> 0.815</td> <td>   -0.098</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Open_Smart</th>                             <td>   -0.0364</td> <td>    0.032</td> <td>   -1.136</td> <td> 0.256</td> <td>   -0.099</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PIP_Program</th>                            <td>    0.0075</td> <td>    0.037</td> <td>    0.203</td> <td> 0.839</td> <td>   -0.065</td> <td>    0.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PQS_Program</th>                            <td>   -0.0227</td> <td>    0.043</td> <td>   -0.531</td> <td> 0.596</td> <td>   -0.106</td> <td>    0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SCS_Program</th>                            <td>    0.1016</td> <td>    0.039</td> <td>    2.593</td> <td> 0.010</td> <td>    0.025</td> <td>    0.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Spar_Coverage_Ind</th>                      <td>   -0.0093</td> <td>    0.039</td> <td>   -0.241</td> <td> 0.810</td> <td>   -0.085</td> <td>    0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Specialty_Solutions</th>                    <td>   -0.1235</td> <td>    0.031</td> <td>   -3.933</td> <td> 0.000</td> <td>   -0.185</td> <td>   -0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Vaccine_Items</th>                          <td>   -0.0185</td> <td>    0.040</td> <td>   -0.464</td> <td> 0.643</td> <td>   -0.097</td> <td>    0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Vaccine_Starter</th>                        <td>    0.0108</td> <td>    0.030</td> <td>    0.364</td> <td> 0.716</td> <td>   -0.048</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Vaccine_Items_Count</th>                    <td>   -0.0270</td> <td>    0.047</td> <td>   -0.572</td> <td> 0.567</td> <td>   -0.119</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Vaccine_Items_Sls_Amt</th>                  <td>    0.0909</td> <td>    0.044</td> <td>    2.081</td> <td> 0.037</td> <td>    0.005</td> <td>    0.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>YPO</th>                                    <td>    0.0070</td> <td>    0.034</td> <td>    0.208</td> <td> 0.835</td> <td>   -0.059</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tot_Sls_Amt</th>                            <td>    0.0291</td> <td>    0.031</td> <td>    0.950</td> <td> 0.342</td> <td>   -0.031</td> <td>    0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DLC_Program_encoded</th>                    <td>    0.0067</td> <td>    0.036</td> <td>    0.185</td> <td> 0.853</td> <td>   -0.065</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FEM_Program_encoded</th>                    <td>    0.0417</td> <td>    0.047</td> <td>    0.891</td> <td> 0.373</td> <td>   -0.050</td> <td>    0.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HM_Circular_Program_encoded</th>            <td>   -0.0517</td> <td>    0.035</td> <td>   -1.491</td> <td> 0.136</td> <td>   -0.120</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Internal_Decor</th>                         <td>    0.0405</td> <td>    0.042</td> <td>    0.955</td> <td> 0.340</td> <td>   -0.043</td> <td>    0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PQS_Enrolled_encoded</th>                   <td>   -0.0658</td> <td>    0.041</td> <td>   -1.620</td> <td> 0.105</td> <td>   -0.145</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ST_encoded</th>                             <td>    0.0614</td> <td>    0.032</td> <td>    1.921</td> <td> 0.055</td> <td>   -0.001</td> <td>    0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pog_Code_Name_encoded</th>                  <td>   -0.0687</td> <td>    0.033</td> <td>   -2.099</td> <td> 0.036</td> <td>   -0.133</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DC_Name_encoded</th>                        <td>    0.1028</td> <td>    0.031</td> <td>    3.324</td> <td> 0.001</td> <td>    0.042</td> <td>    0.163</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Bus_Type_Desc_encoded</th>                  <td>    0.0454</td> <td>    0.031</td> <td>    1.447</td> <td> 0.148</td> <td>   -0.016</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Region_encoded</th>                         <td>   -0.1771</td> <td>    0.038</td> <td>   -4.659</td> <td> 0.000</td> <td>   -0.252</td> <td>   -0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PSAO_Expanded_encoded</th>                  <td>   -0.0170</td> <td>    0.050</td> <td>   -0.344</td> <td> 0.731</td> <td>   -0.114</td> <td>    0.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Chain_Name_encoded</th>                     <td>    0.0637</td> <td>    0.033</td> <td>    1.953</td> <td> 0.051</td> <td>   -0.000</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Salesperson_encoded</th>                    <td>   -0.0238</td> <td>    0.030</td> <td>   -0.790</td> <td> 0.429</td> <td>   -0.083</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AH_Program_encoded</th>                     <td>    0.0407</td> <td>    0.051</td> <td>    0.801</td> <td> 0.423</td> <td>   -0.059</td> <td>    0.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OTC_Front-end_Size_encoded</th>             <td>   -0.0695</td> <td>    0.042</td> <td>   -1.667</td> <td> 0.096</td> <td>   -0.151</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MRA_Program_Type_-_Active_AH_encoded</th>   <td>   -0.1145</td> <td>    0.034</td> <td>   -3.358</td> <td> 0.001</td> <td>   -0.181</td> <td>   -0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Msa_Dma_encoded</th>                        <td>    0.2944</td> <td>    0.038</td> <td>    7.660</td> <td> 0.000</td> <td>    0.219</td> <td>    0.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Signage_Program_encoded</th>                <td>    0.0062</td> <td>    0.036</td> <td>    0.176</td> <td> 0.860</td> <td>   -0.063</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Brand_pct</th>                              <td> 3.696e-09</td> <td> 6.93e-09</td> <td>    0.534</td> <td> 0.594</td> <td>-9.88e-09</td> <td> 1.73e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Generic_pct</th>                            <td>-2.827e-08</td> <td>  2.4e-08</td> <td>   -1.179</td> <td> 0.238</td> <td>-7.53e-08</td> <td> 1.87e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Otc_pct</th>                                <td> 8.864e-08</td> <td> 6.75e-08</td> <td>    1.312</td> <td> 0.189</td> <td>-4.38e-08</td> <td> 2.21e-07</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:            340B_Active   No. Observations:                 4846\n",
       "Model:                          Logit   Df Residuals:                     4807\n",
       "Method:                           MLE   Df Model:                           38\n",
       "Date:                Thu, 29 Mar 2018   Pseudo R-squ.:                 -0.4412\n",
       "Time:                        11:49:38   Log-Likelihood:                -3222.8\n",
       "converged:                       True   LL-Null:                       -2236.3\n",
       "                                        LLR p-value:                     1.000\n",
       "==========================================================================================================\n",
       "                                             coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------------------\n",
       "Auto_Ship_Ind                              0.0940      0.033      2.828      0.005       0.029       0.159\n",
       "Interior_Decor_Signage_Available_Funds     0.0132      0.041      0.325      0.745      -0.067       0.093\n",
       "LMS_Enrolled                               0.0182      0.035      0.520      0.603      -0.050       0.087\n",
       "LMS_Available_Matching_Funds               0.1136      0.035      3.265      0.001       0.045       0.182\n",
       "LMS_Used_Funds_Most_Recent_3_Months        0.0288      0.044      0.648      0.517      -0.058       0.116\n",
       "LMS_Used_Funds_Previous_3_Months          -0.0104      0.044     -0.234      0.815      -0.098       0.077\n",
       "Open_Smart                                -0.0364      0.032     -1.136      0.256      -0.099       0.026\n",
       "PIP_Program                                0.0075      0.037      0.203      0.839      -0.065       0.080\n",
       "PQS_Program                               -0.0227      0.043     -0.531      0.596      -0.106       0.061\n",
       "SCS_Program                                0.1016      0.039      2.593      0.010       0.025       0.178\n",
       "Spar_Coverage_Ind                         -0.0093      0.039     -0.241      0.810      -0.085       0.066\n",
       "Specialty_Solutions                       -0.1235      0.031     -3.933      0.000      -0.185      -0.062\n",
       "Vaccine_Items                             -0.0185      0.040     -0.464      0.643      -0.097       0.060\n",
       "Vaccine_Starter                            0.0108      0.030      0.364      0.716      -0.048       0.069\n",
       "Vaccine_Items_Count                       -0.0270      0.047     -0.572      0.567      -0.119       0.065\n",
       "Vaccine_Items_Sls_Amt                      0.0909      0.044      2.081      0.037       0.005       0.177\n",
       "YPO                                        0.0070      0.034      0.208      0.835      -0.059       0.073\n",
       "Tot_Sls_Amt                                0.0291      0.031      0.950      0.342      -0.031       0.089\n",
       "DLC_Program_encoded                        0.0067      0.036      0.185      0.853      -0.065       0.078\n",
       "FEM_Program_encoded                        0.0417      0.047      0.891      0.373      -0.050       0.134\n",
       "HM_Circular_Program_encoded               -0.0517      0.035     -1.491      0.136      -0.120       0.016\n",
       "Internal_Decor                             0.0405      0.042      0.955      0.340      -0.043       0.124\n",
       "PQS_Enrolled_encoded                      -0.0658      0.041     -1.620      0.105      -0.145       0.014\n",
       "ST_encoded                                 0.0614      0.032      1.921      0.055      -0.001       0.124\n",
       "Pog_Code_Name_encoded                     -0.0687      0.033     -2.099      0.036      -0.133      -0.005\n",
       "DC_Name_encoded                            0.1028      0.031      3.324      0.001       0.042       0.163\n",
       "Bus_Type_Desc_encoded                      0.0454      0.031      1.447      0.148      -0.016       0.107\n",
       "Region_encoded                            -0.1771      0.038     -4.659      0.000      -0.252      -0.103\n",
       "PSAO_Expanded_encoded                     -0.0170      0.050     -0.344      0.731      -0.114       0.080\n",
       "Chain_Name_encoded                         0.0637      0.033      1.953      0.051      -0.000       0.128\n",
       "Salesperson_encoded                       -0.0238      0.030     -0.790      0.429      -0.083       0.035\n",
       "AH_Program_encoded                         0.0407      0.051      0.801      0.423      -0.059       0.140\n",
       "OTC_Front-end_Size_encoded                -0.0695      0.042     -1.667      0.096      -0.151       0.012\n",
       "MRA_Program_Type_-_Active_AH_encoded      -0.1145      0.034     -3.358      0.001      -0.181      -0.048\n",
       "Msa_Dma_encoded                            0.2944      0.038      7.660      0.000       0.219       0.370\n",
       "Signage_Program_encoded                    0.0062      0.036      0.176      0.860      -0.063       0.076\n",
       "Brand_pct                               3.696e-09   6.93e-09      0.534      0.594   -9.88e-09    1.73e-08\n",
       "Generic_pct                            -2.827e-08    2.4e-08     -1.179      0.238   -7.53e-08    1.87e-08\n",
       "Otc_pct                                 8.864e-08   6.75e-08      1.312      0.189   -4.38e-08    2.21e-07\n",
       "==========================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.Logit(y, X)\n",
    "result = model.fit()\n",
    "result.summary ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce the dimensions even further, based on Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick the top features to model, making the model simpler but still performing as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XR = X[['DC_Name_encoded','Tot_Sls_Amt', 'Msa_Dma_encoded',\n",
    "                'Salesperson_encoded', 'ST_encoded',\n",
    "                'Chain_Name_encoded','LMS_Available_Matching_Funds', 'Otc_pct', 'Brand_pct', 'Generic_pct']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XR_train = X_train[['DC_Name_encoded','Tot_Sls_Amt', 'Msa_Dma_encoded',\n",
    "                'Salesperson_encoded', 'ST_encoded',\n",
    "                'Chain_Name_encoded','LMS_Available_Matching_Funds', 'Otc_pct', 'Brand_pct', 'Generic_pct']]\n",
    "\n",
    "XR_test = X_test[['DC_Name_encoded','Tot_Sls_Amt', 'Msa_Dma_encoded',\n",
    "                'Salesperson_encoded', 'ST_encoded',\n",
    "                'Chain_Name_encoded','LMS_Available_Matching_Funds', 'Otc_pct', 'Brand_pct', 'Generic_pct']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score cross-validated:  0.745592687673\n",
      "Recall Score:  0.390681003584\n",
      "Precision Score average:   0.241868564938\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree with reduced features\n",
    "\n",
    "dtr = DecisionTreeClassifier()\n",
    "dtr.fit(XR_train, y_train)\n",
    "dtr.feature_importances_\n",
    "pred_dtr = dtr.predict(XR_test) \n",
    "dtr_score_acc = np.mean(cross_val_score(dtr, XR_test, y_test, cv=5))\n",
    "dtr_score_recall = recall_score(y_test, pred_dtr)\n",
    "dtr_score_avgprecision = average_precision_score(y_test, pred_dtr)\n",
    "\n",
    "print(\"Accuracy Score cross-validated: \", dtr_score_acc)\n",
    "print(\"Recall Score: \", dtr_score_recall)\n",
    "print(\"Precision Score average:  \", dtr_score_avgprecision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Feature Importance\n",
      "DC_Name_encoded                         0.053801\n",
      "Tot_Sls_Amt                             0.162780\n",
      "Msa_Dma_encoded                         0.115122\n",
      "Salesperson_encoded                     0.108340\n",
      "ST_encoded                              0.059430\n",
      "Chain_Name_encoded                      0.059640\n",
      "LMS_Available_Matching_Funds            0.090171\n",
      "Otc_pct                                 0.103767\n",
      "Brand_pct                               0.114002\n",
      "Generic_pct                             0.132946\n"
     ]
    }
   ],
   "source": [
    "feature_imp_dtr = pd.DataFrame({'Feature Importance' : dtr.feature_importances_}, index=XR.columns)\n",
    "print(feature_imp_dtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.679420\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>340B_Active</td>   <th>  No. Observations:  </th>  <td>  4846</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  4836</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Thu, 29 Mar 2018</td> <th>  Pseudo R-squ.:     </th>  <td>-0.4723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>11:55:07</td>     <th>  Log-Likelihood:    </th> <td> -3292.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -2236.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>  <td> 1.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                  <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DC_Name_encoded</th>              <td>    0.0967</td> <td>    0.030</td> <td>    3.275</td> <td> 0.001</td> <td>    0.039</td> <td>    0.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tot_Sls_Amt</th>                  <td>    0.0867</td> <td>    0.033</td> <td>    2.639</td> <td> 0.008</td> <td>    0.022</td> <td>    0.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Msa_Dma_encoded</th>              <td>    0.2064</td> <td>    0.031</td> <td>    6.702</td> <td> 0.000</td> <td>    0.146</td> <td>    0.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Salesperson_encoded</th>          <td>   -0.0289</td> <td>    0.029</td> <td>   -0.982</td> <td> 0.326</td> <td>   -0.086</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ST_encoded</th>                   <td>    0.0865</td> <td>    0.030</td> <td>    2.864</td> <td> 0.004</td> <td>    0.027</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Chain_Name_encoded</th>           <td>    0.0879</td> <td>    0.030</td> <td>    2.885</td> <td> 0.004</td> <td>    0.028</td> <td>    0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LMS_Available_Matching_Funds</th> <td>    0.1741</td> <td>    0.033</td> <td>    5.244</td> <td> 0.000</td> <td>    0.109</td> <td>    0.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Otc_pct</th>                      <td> 8.711e-08</td> <td> 6.69e-08</td> <td>    1.302</td> <td> 0.193</td> <td> -4.4e-08</td> <td> 2.18e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Brand_pct</th>                    <td> 2.282e-09</td> <td>  6.8e-09</td> <td>    0.336</td> <td> 0.737</td> <td> -1.1e-08</td> <td> 1.56e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Generic_pct</th>                  <td>-2.331e-08</td> <td> 2.34e-08</td> <td>   -0.998</td> <td> 0.318</td> <td>-6.91e-08</td> <td> 2.25e-08</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:            340B_Active   No. Observations:                 4846\n",
       "Model:                          Logit   Df Residuals:                     4836\n",
       "Method:                           MLE   Df Model:                            9\n",
       "Date:                Thu, 29 Mar 2018   Pseudo R-squ.:                 -0.4723\n",
       "Time:                        11:55:07   Log-Likelihood:                -3292.5\n",
       "converged:                       True   LL-Null:                       -2236.3\n",
       "                                        LLR p-value:                     1.000\n",
       "================================================================================================\n",
       "                                   coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------\n",
       "DC_Name_encoded                  0.0967      0.030      3.275      0.001       0.039       0.155\n",
       "Tot_Sls_Amt                      0.0867      0.033      2.639      0.008       0.022       0.151\n",
       "Msa_Dma_encoded                  0.2064      0.031      6.702      0.000       0.146       0.267\n",
       "Salesperson_encoded             -0.0289      0.029     -0.982      0.326      -0.086       0.029\n",
       "ST_encoded                       0.0865      0.030      2.864      0.004       0.027       0.146\n",
       "Chain_Name_encoded               0.0879      0.030      2.885      0.004       0.028       0.148\n",
       "LMS_Available_Matching_Funds     0.1741      0.033      5.244      0.000       0.109       0.239\n",
       "Otc_pct                       8.711e-08   6.69e-08      1.302      0.193    -4.4e-08    2.18e-07\n",
       "Brand_pct                     2.282e-09    6.8e-09      0.336      0.737    -1.1e-08    1.56e-08\n",
       "Generic_pct                  -2.331e-08   2.34e-08     -0.998      0.318   -6.91e-08    2.25e-08\n",
       "================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelXR = sm.Logit(y, XR)\n",
    "resultXR = modelXR.fit()\n",
    "resultXR.summary ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF DC_Name_encoded: 1.027215350053756\n",
      "VIF Tot_Sls_Amt: 1.0021491915742353\n",
      "VIF Msa_Dma_encoded: 1.1136712691525015\n",
      "VIF Salesperson_encoded: 1.0214735621955604\n",
      "VIF ST_encoded: 1.0751799944418934\n",
      "VIF Chain_Name_encoded: 1.1054219796981775\n",
      "VIF LMS_Available_Matching_Funds: 1.0128677178826926\n",
      "VIF Otc_pct: 19.663962886832262\n",
      "VIF Brand_pct: 68.57825746098196\n",
      "VIF Generic_pct: 91.64864771792729\n"
     ]
    }
   ],
   "source": [
    "for i, col in enumerate(XR.columns):            # check VIF\n",
    "    print('VIF {}: {}'.format(col,variance_inflation_factor(XR.values,i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new measures for Percent of Sales are highly correlated.  Drop all but one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XR = XR.drop('Otc_pct', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XR = XR.drop('Generic_pct', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF DC_Name_encoded: 1.0266533808341984\n",
      "VIF Tot_Sls_Amt: 1.0020820138878317\n",
      "VIF Msa_Dma_encoded: 1.113663150611752\n",
      "VIF Salesperson_encoded: 1.0212972344299605\n",
      "VIF ST_encoded: 1.074990915190292\n",
      "VIF Chain_Name_encoded: 1.1052467438795437\n",
      "VIF LMS_Available_Matching_Funds: 1.0128326877430391\n",
      "VIF Brand_pct: 1.001189327357945\n"
     ]
    }
   ],
   "source": [
    "for i, col in enumerate(XR.columns):            # check VIF\n",
    "    print('VIF {}: {}'.format(col,variance_inflation_factor(XR.values,i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XR2 = X[['DC_Name_encoded','Auto_Ship_Ind', 'Msa_Dma_encoded',\n",
    "                'SCS_Program', 'Specialty_Solutions','MRA_Program_Type_-_Active_AH_encoded',\n",
    "                'Region_encoded','LMS_Available_Matching_Funds','Brand_pct']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XR2_train = X_train[['DC_Name_encoded','Auto_Ship_Ind', 'Msa_Dma_encoded',\n",
    "                'SCS_Program', 'Specialty_Solutions','MRA_Program_Type_-_Active_AH_encoded',\n",
    "                'Region_encoded','LMS_Available_Matching_Funds','Brand_pct']]\n",
    "\n",
    "XR2_test = X_test[['DC_Name_encoded','Auto_Ship_Ind', 'Msa_Dma_encoded',\n",
    "                'SCS_Program', 'Specialty_Solutions','MRA_Program_Type_-_Active_AH_encoded',\n",
    "                'Region_encoded','LMS_Available_Matching_Funds','Brand_pct']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.669323\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>340B_Active</td>   <th>  No. Observations:  </th>  <td>  4846</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  4837</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Thu, 29 Mar 2018</td> <th>  Pseudo R-squ.:     </th>  <td>-0.4504</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>11:58:26</td>     <th>  Log-Likelihood:    </th> <td> -3243.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -2236.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>  <td> 1.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                    <td></td>                      <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DC_Name_encoded</th>                      <td>    0.0993</td> <td>    0.030</td> <td>    3.357</td> <td> 0.001</td> <td>    0.041</td> <td>    0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Auto_Ship_Ind</th>                        <td>    0.0941</td> <td>    0.030</td> <td>    3.144</td> <td> 0.002</td> <td>    0.035</td> <td>    0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Msa_Dma_encoded</th>                      <td>    0.3056</td> <td>    0.036</td> <td>    8.534</td> <td> 0.000</td> <td>    0.235</td> <td>    0.376</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SCS_Program</th>                          <td>    0.1433</td> <td>    0.031</td> <td>    4.601</td> <td> 0.000</td> <td>    0.082</td> <td>    0.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Specialty_Solutions</th>                  <td>   -0.1190</td> <td>    0.031</td> <td>   -3.845</td> <td> 0.000</td> <td>   -0.180</td> <td>   -0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MRA_Program_Type_-_Active_AH_encoded</th> <td>   -0.1496</td> <td>    0.031</td> <td>   -4.779</td> <td> 0.000</td> <td>   -0.211</td> <td>   -0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Region_encoded</th>                       <td>   -0.1971</td> <td>    0.037</td> <td>   -5.398</td> <td> 0.000</td> <td>   -0.269</td> <td>   -0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LMS_Available_Matching_Funds</th>         <td>    0.1276</td> <td>    0.033</td> <td>    3.834</td> <td> 0.000</td> <td>    0.062</td> <td>    0.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Brand_pct</th>                            <td>-1.455e-10</td> <td> 7.51e-10</td> <td>   -0.194</td> <td> 0.846</td> <td>-1.62e-09</td> <td> 1.33e-09</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:            340B_Active   No. Observations:                 4846\n",
       "Model:                          Logit   Df Residuals:                     4837\n",
       "Method:                           MLE   Df Model:                            8\n",
       "Date:                Thu, 29 Mar 2018   Pseudo R-squ.:                 -0.4504\n",
       "Time:                        11:58:26   Log-Likelihood:                -3243.5\n",
       "converged:                       True   LL-Null:                       -2236.3\n",
       "                                        LLR p-value:                     1.000\n",
       "========================================================================================================\n",
       "                                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------------------\n",
       "DC_Name_encoded                          0.0993      0.030      3.357      0.001       0.041       0.157\n",
       "Auto_Ship_Ind                            0.0941      0.030      3.144      0.002       0.035       0.153\n",
       "Msa_Dma_encoded                          0.3056      0.036      8.534      0.000       0.235       0.376\n",
       "SCS_Program                              0.1433      0.031      4.601      0.000       0.082       0.204\n",
       "Specialty_Solutions                     -0.1190      0.031     -3.845      0.000      -0.180      -0.058\n",
       "MRA_Program_Type_-_Active_AH_encoded    -0.1496      0.031     -4.779      0.000      -0.211      -0.088\n",
       "Region_encoded                          -0.1971      0.037     -5.398      0.000      -0.269      -0.126\n",
       "LMS_Available_Matching_Funds             0.1276      0.033      3.834      0.000       0.062       0.193\n",
       "Brand_pct                            -1.455e-10   7.51e-10     -0.194      0.846   -1.62e-09    1.33e-09\n",
       "========================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelXR2 = sm.Logit(y, XR2)\n",
    "resultXR2 = modelXR2.fit()\n",
    "resultXR2.summary ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch to optimize the model, using the reduced feature set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we optimized the model that seems to perform the best?   We try many parameters via GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for defining a tree:\n",
    "\n",
    "1.min_samples_split ◦Defines the minimum number of samples (or observations) which are required in a node to be considered for splitting.\n",
    "◦Used to control over-fitting. Higher values prevent a model from learning relations which might be highly specific to the particular sample selected for a tree.\n",
    "◦Too high values can lead to under-fitting hence, it should be tuned using CV.\n",
    "\n",
    "2.min_samples_leaf ◦Defines the minimum samples (or observations) required in a terminal node or leaf.\n",
    "◦Used to control over-fitting similar to min_samples_split.\n",
    "◦Generally lower values should be chosen for imbalanced class problems because the regions in which the minority class will be in majority will be very small.\n",
    "\n",
    "3.min_weight_fraction_leaf ◦Similar to min_samples_leaf but defined as a fraction of the total number of observations instead of an integer.\n",
    "◦Only one of #2 and #3 should be defined.\n",
    "\n",
    "4.max_depth ◦The maximum depth of a tree.\n",
    "◦Used to control over-fitting as higher depth will allow model to learn relations very specific to a particular sample.\n",
    "◦Should be tuned using CV.\n",
    "\n",
    "5.max_leaf_nodes ◦The maximum number of terminal nodes or leaves in a tree.\n",
    "◦Can be defined in place of max_depth. Since binary trees are created, a depth of ‘n’ would produce a maximum of 2^n leaves.\n",
    "◦If this is defined, GBM will ignore max_depth.\n",
    "\n",
    "6.max_features ◦The number of features to consider while searching for a best split. These will be randomly selected.\n",
    "◦As a thumb-rule, square root of the total number of features works great but we should check upto 30-40% of the total number of features.\n",
    "◦Higher values can lead to over-fitting but depends on case to case.\n",
    "\n",
    "Parameters for managing boosting:\n",
    "    \n",
    "1.learning_rate ◦This determines the impact of each tree on the final outcome (step 2.4). GBM works by starting with an initial estimate which is updated using the output of each tree. The learning parameter controls the magnitude of this change in the estimates.\n",
    "◦Lower values are generally preferred as they make the model robust to the specific characteristics of tree and thus allowing it to generalize well.\n",
    "◦Lower values would require higher number of trees to model all the relations and will be computationally expensive.\n",
    "\n",
    "2.n_estimators ◦The number of sequential trees to be modeled (step 2)\n",
    "◦Though GBM is fairly robust at higher number of trees but it can still overfit at a point. Hence, this should be tuned using CV for a particular learning rate.\n",
    "\n",
    "3.subsample ◦The fraction of observations to be selected for each tree. Selection is done by random sampling.\n",
    "◦Values slightly less than 1 make the model robust by reducing the variance.\n",
    "◦Typical values ~0.8 generally work fine but can be fine-tuned further.\n",
    "\n",
    "\n",
    "Miscellaneous parameters:\n",
    "    \n",
    "1.loss ◦It refers to the loss function to be minimized in each split.\n",
    "◦It can have various values for classification and regression case. Generally the default values work fine. Other values should be chosen only if you understand their impact on the model.\n",
    "\n",
    "2.init ◦This affects initialization of the output.\n",
    "◦This can be used if we have made another model whose outcome is to be used as the initial estimates for GBM.\n",
    "\n",
    "3.random_state ◦The random number seed so that same random numbers are generated every time.\n",
    "◦This is important for parameter tuning. If we don’t fix the random number, then we’ll have different outcomes for subsequent runs on the same parameters and it becomes difficult to compare models.\n",
    "◦It can potentially result in overfitting to a particular random sample selected. We can try running models for different random samples, which is computationally expensive and generally not used.\n",
    "\n",
    "4.verbose ◦The type of output to be printed when the model fits. The different values can be: ◾0: no output generated (default)\n",
    "◾1: output generated for trees in certain intervals\n",
    "◾>1: output generated for all trees\n",
    "\n",
    "\n",
    "5.warm_start ◦This parameter has an interesting application and can help a lot if used judicially.\n",
    "◦Using this, we can fit additional trees on previous fits of a model. It can save a lot of time and you should explore this option for advanced applications\n",
    "\n",
    "6.presort  ◦ Select whether to presort data for faster splits.\n",
    "◦It makes the selection automatically by default but it can be changed if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbr_params = dict(learning_rate=np.arange(0.1, 0.5, 0.1),\n",
    "                        min_samples_split=np.arange(5,7,1),\n",
    "                        min_samples_leaf=np.arange(3,6,1),\n",
    "                        max_depth=np.arange(2, 5, 1),\n",
    "                        max_features=np.array([1, 2, 3, 4, 5, 6, 7, None, 'auto', 'sqrt', 'log2']),\n",
    "                        n_estimators=np.arange(60, 100, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_gbr = GridSearchCV(estimator=GradientBoostingClassifier(), param_grid=gbr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'learning_rate': array([ 0.1,  0.2,  0.3,  0.4]), 'min_samples_split': array([5, 6]), 'min_samples_leaf': array([3, 4, 5]), 'max_depth': array([2, 3, 4]), 'max_features': array([1, 2, 3, 4, 5, 6, 7, None, 'auto', 'sqrt', 'log2'], dtype=object), 'n_estimators': array([60, 80])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_gbr.fit(XR_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.20000000000000001,\n",
       " 'max_depth': 4,\n",
       " 'max_features': 7,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 80}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_gbr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84072704867529269"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_gbr.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.20000000000000001, loss='deviance',\n",
       "              max_depth=4, max_features=7, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=3, min_samples_split=5,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=80,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_gbr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbest_model = GradientBoostingClassifier(criterion='friedman_mse', init=None,\\n              learning_rate=0.40000000000000002, loss='deviance',\\n              max_depth=3, max_features='log2', max_leaf_nodes=None,\\n              min_impurity_decrease=0.0, min_impurity_split=None,\\n              min_samples_leaf=1, min_samples_split=3,\\n              min_weight_fraction_leaf=0.0, n_estimators=70,\\n              presort='auto', random_state=None, subsample=1.0, verbose=0,\\n              warm_start=False)\\nbest_model.fit(XR_train, y_train)\\n\\n\""
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### This is the original GridSearch settings - orig Model\n",
    "\"\"\"\n",
    "best_model = GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
    "              learning_rate=0.40000000000000002, loss='deviance',\n",
    "              max_depth=3, max_features='log2', max_leaf_nodes=None,\n",
    "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "              min_samples_leaf=1, min_samples_split=3,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=70,\n",
    "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
    "              warm_start=False)\n",
    "best_model.fit(XR_train, y_train)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.2, loss='deviance', max_depth=4,\n",
       "              max_features=7, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=3, min_samples_split=5,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=80,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This is GridSearch with updated settings - Model 2\n",
    "\n",
    "best_model2 = GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
    "              learning_rate=0.20000000000000001, loss='deviance',\n",
    "              max_depth=4, max_features=7, max_leaf_nodes=None,\n",
    "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "              min_samples_leaf=3, min_samples_split=5,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=80,\n",
    "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
    "              warm_start=False)\n",
    "best_model2.fit(XR_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score cross-validated:  0.834250393256\n",
      "Recall Score:  0.833125\n",
      "Precision Score average:   0.263232526882\n"
     ]
    }
   ],
   "source": [
    "best_model2.feature_importances_\n",
    "pred_best_model2 = best_model2.predict(XR_test) \n",
    "best_model2_score_acc = np.mean(cross_val_score(best_model2, XR_train, y_train, cv=5))\n",
    "best_model2_score_recall = recall_score(y_test, pred_best_model2, average='weighted')\n",
    "best_model2_score_avgprecision = average_precision_score(y_test, pred_best_model2)\n",
    "\n",
    "print(\"Accuracy Score cross-validated: \", best_model2_score_acc)\n",
    "print(\"Recall Score: \", best_model2_score_recall)\n",
    "print(\"Precision Score average:  \", best_model2_score_avgprecision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Decision Tree Grid Search (Model 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtr_params = dict(min_samples_split=np.arange(5,7,1),\n",
    "                        min_samples_leaf=np.arange(3,6,1),\n",
    "                        max_depth=np.arange(2, 5, 1),\n",
    "                        max_features=np.array([1, 2, 3, 4, 5, 6, 7, None, 'auto', 'sqrt', 'log2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_dtr = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=dtr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'min_samples_split': array([5, 6]), 'min_samples_leaf': array([3, 4, 5]), 'max_depth': array([2, 3, 4]), 'max_features': array([1, 2, 3, 4, 5, 6, 7, None, 'auto', 'sqrt', 'log2'], dtype=object)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_dtr.fit(XR_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4,\n",
       " 'max_features': 7,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 5}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_dtr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83210104744300672"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_dtr.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
       "            max_features=7, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=3,\n",
       "            min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_dtr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
       "            max_features=7, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=3,\n",
       "            min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model3 = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=7, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "            min_impurity_split=None, min_samples_leaf=3,\n",
    "            min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=None, splitter='best')\n",
    "best_model3.fit(XR_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score cross-validated:  0.82192988702\n",
      "Recall Score:  0.82625\n",
      "Precision Score average:   0.183509787703\n"
     ]
    }
   ],
   "source": [
    "best_model3.feature_importances_\n",
    "pred_best_model3 = best_model3.predict(XR_test) \n",
    "best_model3_score_acc = np.mean(cross_val_score(best_model3, XR_train, y_train, cv=5))\n",
    "best_model3_score_recall = recall_score(y_test, pred_best_model3, average='weighted')\n",
    "best_model3_score_avgprecision = average_precision_score(y_test, pred_best_model3)\n",
    "\n",
    "print(\"Accuracy Score cross-validated: \", best_model3_score_acc)\n",
    "print(\"Recall Score: \", best_model3_score_recall)\n",
    "print(\"Precision Score average:  \", best_model3_score_avgprecision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model (reduced feature set) on ALL observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We trained and fitted the model with a reduced set of observations (to address the class imbalance for the label), so now we want to try the model on all observations, to learn which pharmacies it predicts as contract pharmacies for Macro Helix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XR_all_obs = X[['DC_Name_encoded', 'Tot_Sls_Amt', 'Msa_Dma_encoded',\n",
    "                'Salesperson_encoded', 'ST_encoded',\n",
    "                'Chain_Name_encoded','LMS_Available_Matching_Funds']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_best_model2_all_obs = best_model2.predict(XR_all_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score cross-validated:  0.178312640303\n",
      "Recall Score:  0.88196450681\n",
      "Recall Score - nt weighted:  0.410225921522\n",
      "Precision Score average:   0.438523341441\n"
     ]
    }
   ],
   "source": [
    "best_model2_all_obs_score_acc = np.mean(cross_val_score(best_model2, XR_all_obs, y, cv=5))\n",
    "best_model2_all_obs_score_recall = recall_score(y, pred_best_model2_all_obs, average='weighted')\n",
    "best_model2_all_obs_score_recall_nw = recall_score(y, pred_best_model2_all_obs) \n",
    "best_model2_all_obs_score_avgprecision = average_precision_score(y, pred_best_model2_all_obs)\n",
    "\n",
    "print(\"Accuracy Score cross-validated: \", best_model2_all_obs_score_acc)\n",
    "print(\"Recall Score: \", best_model2_all_obs_score_recall)\n",
    "print(\"Recall Score - nt weighted: \", best_model2_all_obs_score_recall_nw)\n",
    "print(\"Precision Score average:  \", best_model2_all_obs_score_avgprecision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall score is improved and is GREAT!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put Actual 340B and Predicted 340B into final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_clean['Actual_340B'] = df_clean['340B_Active'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = pred_best_model2_all_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 4425]\n",
      " [   1  421]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(q, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_clean['Predicted_340B'] = pred_best_model2_all_obs           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zip</th>\n",
       "      <th>Hm_Start_Dt</th>\n",
       "      <th>Channel_Type_Cd</th>\n",
       "      <th>Auto_Ship_Ind</th>\n",
       "      <th>Internal_Decor</th>\n",
       "      <th>Interior_Decor_Signage_Available_Funds</th>\n",
       "      <th>LMS_Enrolled</th>\n",
       "      <th>LMS_Available_Matching_Funds</th>\n",
       "      <th>LMS_Used_Funds_Most_Recent_3_Months</th>\n",
       "      <th>LMS_Used_Funds_Previous_3_Months</th>\n",
       "      <th>...</th>\n",
       "      <th>Salesperson_encoded</th>\n",
       "      <th>AH_Program_encoded</th>\n",
       "      <th>OTC_Front-end_Size_encoded</th>\n",
       "      <th>MRA_Program_Type_-_Active_AH_encoded</th>\n",
       "      <th>Msa_Dma_encoded</th>\n",
       "      <th>Signage_Program_encoded</th>\n",
       "      <th>3rd_Party_Vendor_encoded</th>\n",
       "      <th>Hospital_Associated_encoded</th>\n",
       "      <th>Actual_340B</th>\n",
       "      <th>Predicted_340B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Account</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10491</th>\n",
       "      <td>97463</td>\n",
       "      <td>732524</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1724.0</td>\n",
       "      <td>1</td>\n",
       "      <td>822.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17475</th>\n",
       "      <td>97630</td>\n",
       "      <td>732687</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19901</th>\n",
       "      <td>97471</td>\n",
       "      <td>732616</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309745</th>\n",
       "      <td>97467</td>\n",
       "      <td>735998</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652229</th>\n",
       "      <td>97370</td>\n",
       "      <td>734702</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>340.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Zip  Hm_Start_Dt  Channel_Type_Cd  Auto_Ship_Ind  Internal_Decor  \\\n",
       "Account                                                                       \n",
       "10491    97463       732524               30              1               1   \n",
       "17475    97630       732687               30              1               1   \n",
       "19901    97471       732616               30              0               1   \n",
       "309745   97467       735998               30              0               0   \n",
       "652229   97370       734702               30              0               1   \n",
       "\n",
       "         Interior_Decor_Signage_Available_Funds  LMS_Enrolled  \\\n",
       "Account                                                         \n",
       "10491                                    1724.0             1   \n",
       "17475                                       0.0             1   \n",
       "19901                                       0.0             1   \n",
       "309745                                   2500.0             1   \n",
       "652229                                      0.0             1   \n",
       "\n",
       "         LMS_Available_Matching_Funds  LMS_Used_Funds_Most_Recent_3_Months  \\\n",
       "Account                                                                      \n",
       "10491                           822.0                                    1   \n",
       "17475                             0.0                                    1   \n",
       "19901                             0.0                                    1   \n",
       "309745                            0.0                                    0   \n",
       "652229                          340.0                                    1   \n",
       "\n",
       "         LMS_Used_Funds_Previous_3_Months       ...        \\\n",
       "Account                                         ...         \n",
       "10491                                   1       ...         \n",
       "17475                                   1       ...         \n",
       "19901                                   1       ...         \n",
       "309745                                  0       ...         \n",
       "652229                                  0       ...         \n",
       "\n",
       "         Salesperson_encoded  AH_Program_encoded  OTC_Front-end_Size_encoded  \\\n",
       "Account                                                                        \n",
       "10491                      1                   4                           1   \n",
       "17475                      1                   0                           3   \n",
       "19901                      1                   0                           4   \n",
       "309745                     1                   0                           1   \n",
       "652229                     1                   0                           0   \n",
       "\n",
       "         MRA_Program_Type_-_Active_AH_encoded  Msa_Dma_encoded  \\\n",
       "Account                                                          \n",
       "10491                                       7              183   \n",
       "17475                                       3              190   \n",
       "19901                                       2              183   \n",
       "309745                                      8              183   \n",
       "652229                                      8              183   \n",
       "\n",
       "         Signage_Program_encoded  3rd_Party_Vendor_encoded  \\\n",
       "Account                                                      \n",
       "10491                          0                        18   \n",
       "17475                          0                        18   \n",
       "19901                          0                        18   \n",
       "309745                         3                        18   \n",
       "652229                         0                        18   \n",
       "\n",
       "         Hospital_Associated_encoded  Actual_340B  Predicted_340B  \n",
       "Account                                                            \n",
       "10491                             15            0               0  \n",
       "17475                             15            0               0  \n",
       "19901                             15            0               0  \n",
       "309745                            15            0               0  \n",
       "652229                            15            0               0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to file for the business to review predicted contract pharmacies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_clean.to_csv('data/340B_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(df_clean[df_clean['Predicted_340B']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_clean['Predicted_340B'].unique()\n",
    "df_clean['Predicted_340B'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XR_all_obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
