{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "from pandas.core import datetools\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import recall_score, average_precision_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset from Excel file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the files produced in the previous Python notebook that performed cleansing and initial feature reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_unscaled = pd.read_csv('data/HID_features.csv', index_col=0)\n",
    "df_clean = pd.read_csv('data/df_clean.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4846, 36)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_unscaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Auto_Ship_Ind', 'Interior_Decor_Signage_Available_Funds',\n",
       "       'LMS_Enrolled', 'LMS_Available_Matching_Funds',\n",
       "       'LMS_Used_Funds_Most_Recent_3_Months',\n",
       "       'LMS_Used_Funds_Previous_3_Months', 'Open_Smart', 'PIP_Program',\n",
       "       'PQS_Program', 'SCS_Program', 'Spar_Coverage_Ind',\n",
       "       'Specialty_Solutions', 'Vaccine_Items', 'Vaccine_Starter',\n",
       "       'Vaccine_Items_Count', 'Vaccine_Items_Sls_Amt', 'YPO', 'Tot_Sls_Amt',\n",
       "       'DLC_Program_encoded', 'FEM_Program_encoded',\n",
       "       'HM_Circular_Program_encoded', 'Internal_Decor', 'PQS_Enrolled_encoded',\n",
       "       'ST_encoded', 'Pog_Code_Name_encoded', 'DC_Name_encoded',\n",
       "       'Bus_Type_Desc_encoded', 'Region_encoded', 'PSAO_Expanded_encoded',\n",
       "       'Chain_Name_encoded', 'Salesperson_encoded', 'AH_Program_encoded',\n",
       "       'OTC_Front-end_Size_encoded', 'MRA_Program_Type_-_Active_AH_encoded',\n",
       "       'Msa_Dma_encoded', 'Signage_Program_encoded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_unscaled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Auto_Ship_Ind</th>\n",
       "      <th>Interior_Decor_Signage_Available_Funds</th>\n",
       "      <th>LMS_Enrolled</th>\n",
       "      <th>LMS_Available_Matching_Funds</th>\n",
       "      <th>LMS_Used_Funds_Most_Recent_3_Months</th>\n",
       "      <th>LMS_Used_Funds_Previous_3_Months</th>\n",
       "      <th>Open_Smart</th>\n",
       "      <th>PIP_Program</th>\n",
       "      <th>PQS_Program</th>\n",
       "      <th>SCS_Program</th>\n",
       "      <th>...</th>\n",
       "      <th>Bus_Type_Desc_encoded</th>\n",
       "      <th>Region_encoded</th>\n",
       "      <th>PSAO_Expanded_encoded</th>\n",
       "      <th>Chain_Name_encoded</th>\n",
       "      <th>Salesperson_encoded</th>\n",
       "      <th>AH_Program_encoded</th>\n",
       "      <th>OTC_Front-end_Size_encoded</th>\n",
       "      <th>MRA_Program_Type_-_Active_AH_encoded</th>\n",
       "      <th>Msa_Dma_encoded</th>\n",
       "      <th>Signage_Program_encoded</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Account</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10491</th>\n",
       "      <td>1</td>\n",
       "      <td>1724.0</td>\n",
       "      <td>1</td>\n",
       "      <td>822.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17475</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19901</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309745</th>\n",
       "      <td>0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652229</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>340.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Auto_Ship_Ind  Interior_Decor_Signage_Available_Funds  LMS_Enrolled  \\\n",
       "Account                                                                        \n",
       "10491                1                                  1724.0             1   \n",
       "17475                1                                     0.0             1   \n",
       "19901                0                                     0.0             1   \n",
       "309745               0                                  2500.0             1   \n",
       "652229               0                                     0.0             1   \n",
       "\n",
       "         LMS_Available_Matching_Funds  LMS_Used_Funds_Most_Recent_3_Months  \\\n",
       "Account                                                                      \n",
       "10491                           822.0                                    1   \n",
       "17475                             0.0                                    1   \n",
       "19901                             0.0                                    1   \n",
       "309745                            0.0                                    0   \n",
       "652229                          340.0                                    1   \n",
       "\n",
       "         LMS_Used_Funds_Previous_3_Months  Open_Smart  PIP_Program  \\\n",
       "Account                                                              \n",
       "10491                                   1           0            1   \n",
       "17475                                   1           0            0   \n",
       "19901                                   1           0            1   \n",
       "309745                                  0           0            0   \n",
       "652229                                  0           0            0   \n",
       "\n",
       "         PQS_Program  SCS_Program           ...             \\\n",
       "Account                                     ...              \n",
       "10491              1            1           ...              \n",
       "17475              1            1           ...              \n",
       "19901              1            1           ...              \n",
       "309745             0            0           ...              \n",
       "652229             1            0           ...              \n",
       "\n",
       "         Bus_Type_Desc_encoded  Region_encoded  PSAO_Expanded_encoded  \\\n",
       "Account                                                                 \n",
       "10491                        0               3                     16   \n",
       "17475                        0               3                      0   \n",
       "19901                        0               3                      0   \n",
       "309745                       0               3                      0   \n",
       "652229                       0               3                      0   \n",
       "\n",
       "         Chain_Name_encoded  Salesperson_encoded  AH_Program_encoded  \\\n",
       "Account                                                                \n",
       "10491                    39                    1                   4   \n",
       "17475                    39                    1                   0   \n",
       "19901                    39                    1                   0   \n",
       "309745                   39                    1                   0   \n",
       "652229                   38                    1                   0   \n",
       "\n",
       "         OTC_Front-end_Size_encoded  MRA_Program_Type_-_Active_AH_encoded  \\\n",
       "Account                                                                     \n",
       "10491                             1                                     7   \n",
       "17475                             3                                     3   \n",
       "19901                             4                                     2   \n",
       "309745                            1                                     8   \n",
       "652229                            0                                     8   \n",
       "\n",
       "         Msa_Dma_encoded  Signage_Program_encoded  \n",
       "Account                                            \n",
       "10491                183                        0  \n",
       "17475                190                        0  \n",
       "19901                183                        0  \n",
       "309745               183                        3  \n",
       "652229               183                        0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_unscaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df_clean['340B_Active']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try some models and look at performance metrics and important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_unscaled)\n",
    "scaled_features = scaler.transform(X_unscaled)\n",
    "X = pd.DataFrame(scaled_features,columns=X_unscaled.columns, index=X_unscaled.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4846, 36)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Auto_Ship_Ind</th>\n",
       "      <th>Interior_Decor_Signage_Available_Funds</th>\n",
       "      <th>LMS_Enrolled</th>\n",
       "      <th>LMS_Available_Matching_Funds</th>\n",
       "      <th>LMS_Used_Funds_Most_Recent_3_Months</th>\n",
       "      <th>LMS_Used_Funds_Previous_3_Months</th>\n",
       "      <th>Open_Smart</th>\n",
       "      <th>PIP_Program</th>\n",
       "      <th>PQS_Program</th>\n",
       "      <th>SCS_Program</th>\n",
       "      <th>...</th>\n",
       "      <th>Bus_Type_Desc_encoded</th>\n",
       "      <th>Region_encoded</th>\n",
       "      <th>PSAO_Expanded_encoded</th>\n",
       "      <th>Chain_Name_encoded</th>\n",
       "      <th>Salesperson_encoded</th>\n",
       "      <th>AH_Program_encoded</th>\n",
       "      <th>OTC_Front-end_Size_encoded</th>\n",
       "      <th>MRA_Program_Type_-_Active_AH_encoded</th>\n",
       "      <th>Msa_Dma_encoded</th>\n",
       "      <th>Signage_Program_encoded</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Account</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10491</th>\n",
       "      <td>1.266482</td>\n",
       "      <td>0.378602</td>\n",
       "      <td>0.471375</td>\n",
       "      <td>-0.227769</td>\n",
       "      <td>1.417723</td>\n",
       "      <td>1.438413</td>\n",
       "      <td>-0.29872</td>\n",
       "      <td>1.557934</td>\n",
       "      <td>0.578780</td>\n",
       "      <td>0.871930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.187447</td>\n",
       "      <td>1.450286</td>\n",
       "      <td>3.431431</td>\n",
       "      <td>0.974998</td>\n",
       "      <td>-1.695111</td>\n",
       "      <td>2.785719</td>\n",
       "      <td>-0.900617</td>\n",
       "      <td>0.488720</td>\n",
       "      <td>1.538394</td>\n",
       "      <td>-1.191011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17475</th>\n",
       "      <td>1.266482</td>\n",
       "      <td>-1.245755</td>\n",
       "      <td>0.471375</td>\n",
       "      <td>-0.599414</td>\n",
       "      <td>1.417723</td>\n",
       "      <td>1.438413</td>\n",
       "      <td>-0.29872</td>\n",
       "      <td>-0.641876</td>\n",
       "      <td>0.578780</td>\n",
       "      <td>0.871930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.187447</td>\n",
       "      <td>1.450286</td>\n",
       "      <td>-0.368061</td>\n",
       "      <td>0.974998</td>\n",
       "      <td>-1.695111</td>\n",
       "      <td>-0.456453</td>\n",
       "      <td>0.065811</td>\n",
       "      <td>-1.154818</td>\n",
       "      <td>1.650666</td>\n",
       "      <td>-1.191011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19901</th>\n",
       "      <td>-0.789589</td>\n",
       "      <td>-1.245755</td>\n",
       "      <td>0.471375</td>\n",
       "      <td>-0.599414</td>\n",
       "      <td>1.417723</td>\n",
       "      <td>1.438413</td>\n",
       "      <td>-0.29872</td>\n",
       "      <td>1.557934</td>\n",
       "      <td>0.578780</td>\n",
       "      <td>0.871930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.187447</td>\n",
       "      <td>1.450286</td>\n",
       "      <td>-0.368061</td>\n",
       "      <td>0.974998</td>\n",
       "      <td>-1.695111</td>\n",
       "      <td>-0.456453</td>\n",
       "      <td>0.549025</td>\n",
       "      <td>-1.565702</td>\n",
       "      <td>1.538394</td>\n",
       "      <td>-1.191011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309745</th>\n",
       "      <td>-0.789589</td>\n",
       "      <td>1.109752</td>\n",
       "      <td>0.471375</td>\n",
       "      <td>-0.599414</td>\n",
       "      <td>-0.705357</td>\n",
       "      <td>-0.695211</td>\n",
       "      <td>-0.29872</td>\n",
       "      <td>-0.641876</td>\n",
       "      <td>-1.727772</td>\n",
       "      <td>-1.146881</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.187447</td>\n",
       "      <td>1.450286</td>\n",
       "      <td>-0.368061</td>\n",
       "      <td>0.974998</td>\n",
       "      <td>-1.695111</td>\n",
       "      <td>-0.456453</td>\n",
       "      <td>-0.900617</td>\n",
       "      <td>0.899605</td>\n",
       "      <td>1.538394</td>\n",
       "      <td>1.533602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652229</th>\n",
       "      <td>-0.789589</td>\n",
       "      <td>-1.245755</td>\n",
       "      <td>0.471375</td>\n",
       "      <td>-0.445692</td>\n",
       "      <td>1.417723</td>\n",
       "      <td>-0.695211</td>\n",
       "      <td>-0.29872</td>\n",
       "      <td>-0.641876</td>\n",
       "      <td>0.578780</td>\n",
       "      <td>-1.146881</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.187447</td>\n",
       "      <td>1.450286</td>\n",
       "      <td>-0.368061</td>\n",
       "      <td>0.913989</td>\n",
       "      <td>-1.695111</td>\n",
       "      <td>-0.456453</td>\n",
       "      <td>-1.383831</td>\n",
       "      <td>0.899605</td>\n",
       "      <td>1.538394</td>\n",
       "      <td>-1.191011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Auto_Ship_Ind  Interior_Decor_Signage_Available_Funds  LMS_Enrolled  \\\n",
       "Account                                                                        \n",
       "10491         1.266482                                0.378602      0.471375   \n",
       "17475         1.266482                               -1.245755      0.471375   \n",
       "19901        -0.789589                               -1.245755      0.471375   \n",
       "309745       -0.789589                                1.109752      0.471375   \n",
       "652229       -0.789589                               -1.245755      0.471375   \n",
       "\n",
       "         LMS_Available_Matching_Funds  LMS_Used_Funds_Most_Recent_3_Months  \\\n",
       "Account                                                                      \n",
       "10491                       -0.227769                             1.417723   \n",
       "17475                       -0.599414                             1.417723   \n",
       "19901                       -0.599414                             1.417723   \n",
       "309745                      -0.599414                            -0.705357   \n",
       "652229                      -0.445692                             1.417723   \n",
       "\n",
       "         LMS_Used_Funds_Previous_3_Months  Open_Smart  PIP_Program  \\\n",
       "Account                                                              \n",
       "10491                            1.438413    -0.29872     1.557934   \n",
       "17475                            1.438413    -0.29872    -0.641876   \n",
       "19901                            1.438413    -0.29872     1.557934   \n",
       "309745                          -0.695211    -0.29872    -0.641876   \n",
       "652229                          -0.695211    -0.29872    -0.641876   \n",
       "\n",
       "         PQS_Program  SCS_Program           ...             \\\n",
       "Account                                     ...              \n",
       "10491       0.578780     0.871930           ...              \n",
       "17475       0.578780     0.871930           ...              \n",
       "19901       0.578780     0.871930           ...              \n",
       "309745     -1.727772    -1.146881           ...              \n",
       "652229      0.578780    -1.146881           ...              \n",
       "\n",
       "         Bus_Type_Desc_encoded  Region_encoded  PSAO_Expanded_encoded  \\\n",
       "Account                                                                 \n",
       "10491                -0.187447        1.450286               3.431431   \n",
       "17475                -0.187447        1.450286              -0.368061   \n",
       "19901                -0.187447        1.450286              -0.368061   \n",
       "309745               -0.187447        1.450286              -0.368061   \n",
       "652229               -0.187447        1.450286              -0.368061   \n",
       "\n",
       "         Chain_Name_encoded  Salesperson_encoded  AH_Program_encoded  \\\n",
       "Account                                                                \n",
       "10491              0.974998            -1.695111            2.785719   \n",
       "17475              0.974998            -1.695111           -0.456453   \n",
       "19901              0.974998            -1.695111           -0.456453   \n",
       "309745             0.974998            -1.695111           -0.456453   \n",
       "652229             0.913989            -1.695111           -0.456453   \n",
       "\n",
       "         OTC_Front-end_Size_encoded  MRA_Program_Type_-_Active_AH_encoded  \\\n",
       "Account                                                                     \n",
       "10491                     -0.900617                              0.488720   \n",
       "17475                      0.065811                             -1.154818   \n",
       "19901                      0.549025                             -1.565702   \n",
       "309745                    -0.900617                              0.899605   \n",
       "652229                    -1.383831                              0.899605   \n",
       "\n",
       "         Msa_Dma_encoded  Signage_Program_encoded  \n",
       "Account                                            \n",
       "10491           1.538394                -1.191011  \n",
       "17475           1.650666                -1.191011  \n",
       "19901           1.538394                -1.191011  \n",
       "309745          1.538394                 1.533602  \n",
       "652229          1.538394                -1.191011  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into train-test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score cross-validated:  0.835480217209\n",
      "Recall Score:  0.186379928315\n",
      "Precision Score average:   0.246087433037\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "rf.feature_importances_\n",
    "pred_rf = rf.predict(X_test) \n",
    "rf_score_acc = np.mean(cross_val_score(rf, X_train, y_train, cv=5))\n",
    "rf_score_recall = recall_score(y_test, pred_rf)\n",
    "rf_score_avgprecision = average_precision_score(y_test, pred_rf)\n",
    "\n",
    "print(\"Accuracy Score cross-validated: \", rf_score_acc)\n",
    "print(\"Recall Score: \", rf_score_recall)\n",
    "print(\"Precision Score average:  \", rf_score_avgprecision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important measure for this business problem is Recall.  This is because Recall captures how many actual Positives the model finds.  In other words, does the model correctly predict current contract pharmacies of Macro Helix?   We want a model that can recognize an actual contract pharmacy.  Precision is not as important, as this captures how many the model labels as positive, compared to how many of those actually are positive; since we know that most of the pharmacies are not currently contract pharmacies, this measure is not very useful to the problem.  Similarly, Accuracy/R2 is not as important because since most in the dataset are negative, the model could merely predict all are negative and have a great Accuracy/R2 score -- not very meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score cross-validated:  0.761554355667\n",
      "Recall Score:  0.379928315412\n",
      "Precision Score average:   0.237203209723\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "dt.feature_importances_\n",
    "pred_dt = dt.predict(X_test) \n",
    "dt_score_acc = np.mean(cross_val_score(dt, X_train, y_train, cv=5))\n",
    "dt_score_recall = recall_score(y_test, pred_dt)\n",
    "dt_score_avgprecision = average_precision_score(y_test, pred_dt)\n",
    "\n",
    "print(\"Accuracy Score cross-validated: \", dt_score_acc)\n",
    "print(\"Recall Score: \", dt_score_recall)\n",
    "print(\"Precision Score average:  \", dt_score_avgprecision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Feature Importance\n",
      "Auto_Ship_Ind                                     0.007996\n",
      "Interior_Decor_Signage_Available_Funds            0.055260\n",
      "LMS_Enrolled                                      0.004314\n",
      "LMS_Available_Matching_Funds                      0.073022\n",
      "LMS_Used_Funds_Most_Recent_3_Months               0.013859\n",
      "LMS_Used_Funds_Previous_3_Months                  0.002598\n",
      "Open_Smart                                        0.005068\n",
      "PIP_Program                                       0.004110\n",
      "PQS_Program                                       0.001811\n",
      "SCS_Program                                       0.013659\n",
      "Spar_Coverage_Ind                                 0.008423\n",
      "Specialty_Solutions                               0.003302\n",
      "Vaccine_Items                                     0.003228\n",
      "Vaccine_Starter                                   0.018222\n",
      "Vaccine_Items_Count                               0.012768\n",
      "Vaccine_Items_Sls_Amt                             0.045144\n",
      "YPO                                               0.008662\n",
      "Tot_Sls_Amt                                       0.145083\n",
      "DLC_Program_encoded                               0.015998\n",
      "FEM_Program_encoded                               0.013111\n",
      "HM_Circular_Program_encoded                       0.015010\n",
      "Internal_Decor                                    0.015513\n",
      "PQS_Enrolled_encoded                              0.002814\n",
      "ST_encoded                                        0.061156\n",
      "Pog_Code_Name_encoded                             0.019019\n",
      "DC_Name_encoded                                   0.036898\n",
      "Bus_Type_Desc_encoded                             0.008321\n",
      "Region_encoded                                    0.014740\n",
      "PSAO_Expanded_encoded                             0.008183\n",
      "Chain_Name_encoded                                0.057542\n",
      "Salesperson_encoded                               0.096198\n",
      "AH_Program_encoded                                0.008180\n",
      "OTC_Front-end_Size_encoded                        0.045685\n",
      "MRA_Program_Type_-_Active_AH_encoded              0.044214\n",
      "Msa_Dma_encoded                                   0.096271\n",
      "Signage_Program_encoded                           0.014616\n"
     ]
    }
   ],
   "source": [
    "feature_imp_dt = pd.DataFrame({'Feature Importance' : dt.feature_importances_}, index=X.columns)\n",
    "print(feature_imp_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score cross-validated:  0.831794072845\n",
      "Recall Score:  0.154121863799\n",
      "Precision Score average:   0.234700528202\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train, y_train)\n",
    "gb.feature_importances_\n",
    "pred_gb = gb.predict(X_test) \n",
    "gb_score_acc = np.mean(cross_val_score(gb, X_train, y_train, cv=5))\n",
    "gb_score_recall = recall_score(y_test, pred_gb)\n",
    "gb_score_avgprecision = average_precision_score(y_test, pred_gb)\n",
    "\n",
    "print(\"Accuracy Score cross-validated: \", gb_score_acc)\n",
    "print(\"Recall Score: \", gb_score_recall)\n",
    "print(\"Precision Score average:  \", gb_score_avgprecision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show which features are most important\n",
    "\n",
    "def plot_feature_importance(model, df):\n",
    "    cols = []\n",
    "    for col in df.columns:\n",
    "        cols.append(col)\n",
    "\n",
    "    feature_importances = pd.DataFrame({'Feature Importance' : model.feature_importances_}, index=cols)\n",
    "    feature_importances = feature_importances.sort_values(by='Feature Importance')\n",
    "    feature_importances.plot(kind='barh', color='r', figsize=(6,6))\n",
    "    plt.title('Feature Importance', fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figures/feat_import.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa0AAAGoCAYAAAD1m7qEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nExoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcb470b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_feature_importance(dt, X_test)              ### drop in the model with best recall here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.665322\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>340B_Active</td>   <th>  No. Observations:  </th>  <td>  4846</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  4810</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>    35</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Wed, 28 Mar 2018</td> <th>  Pseudo R-squ.:     </th>  <td>-0.4418</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>10:38:13</td>     <th>  Log-Likelihood:    </th> <td> -3224.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -2236.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>  <td> 1.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                     <td></td>                       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Auto_Ship_Ind</th>                          <td>    0.0946</td> <td>    0.033</td> <td>    2.847</td> <td> 0.004</td> <td>    0.029</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Interior_Decor_Signage_Available_Funds</th> <td>    0.0144</td> <td>    0.041</td> <td>    0.355</td> <td> 0.723</td> <td>   -0.065</td> <td>    0.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LMS_Enrolled</th>                           <td>    0.0186</td> <td>    0.035</td> <td>    0.531</td> <td> 0.596</td> <td>   -0.050</td> <td>    0.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LMS_Available_Matching_Funds</th>           <td>    0.1133</td> <td>    0.035</td> <td>    3.258</td> <td> 0.001</td> <td>    0.045</td> <td>    0.181</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LMS_Used_Funds_Most_Recent_3_Months</th>    <td>    0.0286</td> <td>    0.044</td> <td>    0.643</td> <td> 0.520</td> <td>   -0.059</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LMS_Used_Funds_Previous_3_Months</th>       <td>   -0.0116</td> <td>    0.044</td> <td>   -0.262</td> <td> 0.794</td> <td>   -0.099</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Open_Smart</th>                             <td>   -0.0361</td> <td>    0.032</td> <td>   -1.128</td> <td> 0.259</td> <td>   -0.099</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PIP_Program</th>                            <td>    0.0069</td> <td>    0.037</td> <td>    0.187</td> <td> 0.852</td> <td>   -0.065</td> <td>    0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PQS_Program</th>                            <td>   -0.0231</td> <td>    0.043</td> <td>   -0.540</td> <td> 0.590</td> <td>   -0.107</td> <td>    0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SCS_Program</th>                            <td>    0.1021</td> <td>    0.039</td> <td>    2.605</td> <td> 0.009</td> <td>    0.025</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Spar_Coverage_Ind</th>                      <td>   -0.0102</td> <td>    0.039</td> <td>   -0.265</td> <td> 0.791</td> <td>   -0.086</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Specialty_Solutions</th>                    <td>   -0.1227</td> <td>    0.031</td> <td>   -3.906</td> <td> 0.000</td> <td>   -0.184</td> <td>   -0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Vaccine_Items</th>                          <td>   -0.0175</td> <td>    0.040</td> <td>   -0.440</td> <td> 0.660</td> <td>   -0.096</td> <td>    0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Vaccine_Starter</th>                        <td>    0.0116</td> <td>    0.030</td> <td>    0.390</td> <td> 0.696</td> <td>   -0.047</td> <td>    0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Vaccine_Items_Count</th>                    <td>   -0.0277</td> <td>    0.047</td> <td>   -0.587</td> <td> 0.557</td> <td>   -0.120</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Vaccine_Items_Sls_Amt</th>                  <td>    0.0909</td> <td>    0.044</td> <td>    2.081</td> <td> 0.037</td> <td>    0.005</td> <td>    0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>YPO</th>                                    <td>    0.0076</td> <td>    0.034</td> <td>    0.228</td> <td> 0.820</td> <td>   -0.058</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tot_Sls_Amt</th>                            <td>    0.0294</td> <td>    0.031</td> <td>    0.960</td> <td> 0.337</td> <td>   -0.031</td> <td>    0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DLC_Program_encoded</th>                    <td>    0.0075</td> <td>    0.036</td> <td>    0.205</td> <td> 0.837</td> <td>   -0.064</td> <td>    0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FEM_Program_encoded</th>                    <td>    0.0414</td> <td>    0.047</td> <td>    0.885</td> <td> 0.376</td> <td>   -0.050</td> <td>    0.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HM_Circular_Program_encoded</th>            <td>   -0.0511</td> <td>    0.035</td> <td>   -1.473</td> <td> 0.141</td> <td>   -0.119</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Internal_Decor</th>                         <td>    0.0396</td> <td>    0.042</td> <td>    0.934</td> <td> 0.350</td> <td>   -0.044</td> <td>    0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PQS_Enrolled_encoded</th>                   <td>   -0.0661</td> <td>    0.041</td> <td>   -1.629</td> <td> 0.103</td> <td>   -0.146</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ST_encoded</th>                             <td>    0.0616</td> <td>    0.032</td> <td>    1.926</td> <td> 0.054</td> <td>   -0.001</td> <td>    0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pog_Code_Name_encoded</th>                  <td>   -0.0683</td> <td>    0.033</td> <td>   -2.088</td> <td> 0.037</td> <td>   -0.132</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DC_Name_encoded</th>                        <td>    0.1031</td> <td>    0.031</td> <td>    3.336</td> <td> 0.001</td> <td>    0.043</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Bus_Type_Desc_encoded</th>                  <td>    0.0454</td> <td>    0.031</td> <td>    1.448</td> <td> 0.148</td> <td>   -0.016</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Region_encoded</th>                         <td>   -0.1781</td> <td>    0.038</td> <td>   -4.689</td> <td> 0.000</td> <td>   -0.253</td> <td>   -0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PSAO_Expanded_encoded</th>                  <td>   -0.0172</td> <td>    0.050</td> <td>   -0.346</td> <td> 0.729</td> <td>   -0.114</td> <td>    0.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Chain_Name_encoded</th>                     <td>    0.0637</td> <td>    0.033</td> <td>    1.956</td> <td> 0.050</td> <td>   -0.000</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Salesperson_encoded</th>                    <td>   -0.0242</td> <td>    0.030</td> <td>   -0.806</td> <td> 0.420</td> <td>   -0.083</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AH_Program_encoded</th>                     <td>    0.0400</td> <td>    0.051</td> <td>    0.787</td> <td> 0.431</td> <td>   -0.060</td> <td>    0.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OTC_Front-end_Size_encoded</th>             <td>   -0.0703</td> <td>    0.042</td> <td>   -1.688</td> <td> 0.091</td> <td>   -0.152</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MRA_Program_Type_-_Active_AH_encoded</th>   <td>   -0.1144</td> <td>    0.034</td> <td>   -3.354</td> <td> 0.001</td> <td>   -0.181</td> <td>   -0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Msa_Dma_encoded</th>                        <td>    0.2949</td> <td>    0.038</td> <td>    7.677</td> <td> 0.000</td> <td>    0.220</td> <td>    0.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Signage_Program_encoded</th>                <td>    0.0060</td> <td>    0.036</td> <td>    0.170</td> <td> 0.865</td> <td>   -0.064</td> <td>    0.076</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:            340B_Active   No. Observations:                 4846\n",
       "Model:                          Logit   Df Residuals:                     4810\n",
       "Method:                           MLE   Df Model:                           35\n",
       "Date:                Wed, 28 Mar 2018   Pseudo R-squ.:                 -0.4418\n",
       "Time:                        10:38:13   Log-Likelihood:                -3224.2\n",
       "converged:                       True   LL-Null:                       -2236.3\n",
       "                                        LLR p-value:                     1.000\n",
       "==========================================================================================================\n",
       "                                             coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------------------\n",
       "Auto_Ship_Ind                              0.0946      0.033      2.847      0.004       0.029       0.160\n",
       "Interior_Decor_Signage_Available_Funds     0.0144      0.041      0.355      0.723      -0.065       0.094\n",
       "LMS_Enrolled                               0.0186      0.035      0.531      0.596      -0.050       0.087\n",
       "LMS_Available_Matching_Funds               0.1133      0.035      3.258      0.001       0.045       0.181\n",
       "LMS_Used_Funds_Most_Recent_3_Months        0.0286      0.044      0.643      0.520      -0.059       0.116\n",
       "LMS_Used_Funds_Previous_3_Months          -0.0116      0.044     -0.262      0.794      -0.099       0.076\n",
       "Open_Smart                                -0.0361      0.032     -1.128      0.259      -0.099       0.027\n",
       "PIP_Program                                0.0069      0.037      0.187      0.852      -0.065       0.079\n",
       "PQS_Program                               -0.0231      0.043     -0.540      0.590      -0.107       0.061\n",
       "SCS_Program                                0.1021      0.039      2.605      0.009       0.025       0.179\n",
       "Spar_Coverage_Ind                         -0.0102      0.039     -0.265      0.791      -0.086       0.065\n",
       "Specialty_Solutions                       -0.1227      0.031     -3.906      0.000      -0.184      -0.061\n",
       "Vaccine_Items                             -0.0175      0.040     -0.440      0.660      -0.096       0.061\n",
       "Vaccine_Starter                            0.0116      0.030      0.390      0.696      -0.047       0.070\n",
       "Vaccine_Items_Count                       -0.0277      0.047     -0.587      0.557      -0.120       0.065\n",
       "Vaccine_Items_Sls_Amt                      0.0909      0.044      2.081      0.037       0.005       0.176\n",
       "YPO                                        0.0076      0.034      0.228      0.820      -0.058       0.073\n",
       "Tot_Sls_Amt                                0.0294      0.031      0.960      0.337      -0.031       0.089\n",
       "DLC_Program_encoded                        0.0075      0.036      0.205      0.837      -0.064       0.079\n",
       "FEM_Program_encoded                        0.0414      0.047      0.885      0.376      -0.050       0.133\n",
       "HM_Circular_Program_encoded               -0.0511      0.035     -1.473      0.141      -0.119       0.017\n",
       "Internal_Decor                             0.0396      0.042      0.934      0.350      -0.044       0.123\n",
       "PQS_Enrolled_encoded                      -0.0661      0.041     -1.629      0.103      -0.146       0.013\n",
       "ST_encoded                                 0.0616      0.032      1.926      0.054      -0.001       0.124\n",
       "Pog_Code_Name_encoded                     -0.0683      0.033     -2.088      0.037      -0.132      -0.004\n",
       "DC_Name_encoded                            0.1031      0.031      3.336      0.001       0.043       0.164\n",
       "Bus_Type_Desc_encoded                      0.0454      0.031      1.448      0.148      -0.016       0.107\n",
       "Region_encoded                            -0.1781      0.038     -4.689      0.000      -0.253      -0.104\n",
       "PSAO_Expanded_encoded                     -0.0172      0.050     -0.346      0.729      -0.114       0.080\n",
       "Chain_Name_encoded                         0.0637      0.033      1.956      0.050      -0.000       0.128\n",
       "Salesperson_encoded                       -0.0242      0.030     -0.806      0.420      -0.083       0.035\n",
       "AH_Program_encoded                         0.0400      0.051      0.787      0.431      -0.060       0.140\n",
       "OTC_Front-end_Size_encoded                -0.0703      0.042     -1.688      0.091      -0.152       0.011\n",
       "MRA_Program_Type_-_Active_AH_encoded      -0.1144      0.034     -3.354      0.001      -0.181      -0.048\n",
       "Msa_Dma_encoded                            0.2949      0.038      7.677      0.000       0.220       0.370\n",
       "Signage_Program_encoded                    0.0060      0.036      0.170      0.865      -0.064       0.076\n",
       "==========================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.Logit(y, X)\n",
    "result = model.fit()\n",
    "result.summary ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce the dimensions even further, based on Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick the top features to model, making the model simpler but still performing as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XR = X[['DC_Name_encoded','Tot_Sls_Amt', 'Msa_Dma_encoded',\n",
    "                'Salesperson_encoded', 'ST_encoded',\n",
    "                'Chain_Name_encoded','LMS_Available_Matching_Funds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XR_train = X_train[['DC_Name_encoded', 'Tot_Sls_Amt', 'Msa_Dma_encoded',\n",
    "                'Salesperson_encoded', 'ST_encoded',\n",
    "                'Chain_Name_encoded','LMS_Available_Matching_Funds']]\n",
    "\n",
    "XR_test = X_test[['DC_Name_encoded', 'Tot_Sls_Amt', 'Msa_Dma_encoded',\n",
    "                'Salesperson_encoded', 'ST_encoded',\n",
    "                'Chain_Name_encoded','LMS_Available_Matching_Funds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score cross-validated:  0.750026294202\n",
      "Recall Score:  0.4229390681\n",
      "Precision Score average:   0.274516324167\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree with reduced features\n",
    "\n",
    "dtr = DecisionTreeClassifier()\n",
    "dtr.fit(XR_train, y_train)\n",
    "dtr.feature_importances_\n",
    "pred_dtr = dtr.predict(XR_test) \n",
    "dtr_score_acc = np.mean(cross_val_score(dtr, XR_test, y_test, cv=5))\n",
    "dtr_score_recall = recall_score(y_test, pred_dtr)\n",
    "dtr_score_avgprecision = average_precision_score(y_test, pred_dtr)\n",
    "\n",
    "print(\"Accuracy Score cross-validated: \", dtr_score_acc)\n",
    "print(\"Recall Score: \", dtr_score_recall)\n",
    "print(\"Precision Score average:  \", dtr_score_avgprecision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Feature Importance\n",
      "DC_Name_encoded                         0.076421\n",
      "Tot_Sls_Amt                             0.226680\n",
      "Msa_Dma_encoded                         0.210651\n",
      "Salesperson_encoded                     0.139562\n",
      "ST_encoded                              0.111419\n",
      "Chain_Name_encoded                      0.082623\n",
      "LMS_Available_Matching_Funds            0.152644\n"
     ]
    }
   ],
   "source": [
    "feature_imp_gbr = pd.DataFrame({'Feature Importance' : gbr.feature_importances_}, index=XR.columns)\n",
    "print(feature_imp_gbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.679674\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>340B_Active</td>   <th>  No. Observations:  </th>  <td>  4846</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  4839</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Wed, 28 Mar 2018</td> <th>  Pseudo R-squ.:     </th>  <td>-0.4729</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>10:45:12</td>     <th>  Log-Likelihood:    </th> <td> -3293.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -2236.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>  <td> 1.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                  <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DC_Name_encoded</th>              <td>    0.0969</td> <td>    0.029</td> <td>    3.285</td> <td> 0.001</td> <td>    0.039</td> <td>    0.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tot_Sls_Amt</th>                  <td>    0.0869</td> <td>    0.033</td> <td>    2.644</td> <td> 0.008</td> <td>    0.022</td> <td>    0.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Msa_Dma_encoded</th>              <td>    0.2063</td> <td>    0.031</td> <td>    6.702</td> <td> 0.000</td> <td>    0.146</td> <td>    0.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Salesperson_encoded</th>          <td>   -0.0292</td> <td>    0.029</td> <td>   -0.995</td> <td> 0.320</td> <td>   -0.087</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ST_encoded</th>                   <td>    0.0867</td> <td>    0.030</td> <td>    2.870</td> <td> 0.004</td> <td>    0.028</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Chain_Name_encoded</th>           <td>    0.0881</td> <td>    0.030</td> <td>    2.892</td> <td> 0.004</td> <td>    0.028</td> <td>    0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LMS_Available_Matching_Funds</th> <td>    0.1738</td> <td>    0.033</td> <td>    5.237</td> <td> 0.000</td> <td>    0.109</td> <td>    0.239</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:            340B_Active   No. Observations:                 4846\n",
       "Model:                          Logit   Df Residuals:                     4839\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Wed, 28 Mar 2018   Pseudo R-squ.:                 -0.4729\n",
       "Time:                        10:45:12   Log-Likelihood:                -3293.7\n",
       "converged:                       True   LL-Null:                       -2236.3\n",
       "                                        LLR p-value:                     1.000\n",
       "================================================================================================\n",
       "                                   coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------\n",
       "DC_Name_encoded                  0.0969      0.029      3.285      0.001       0.039       0.155\n",
       "Tot_Sls_Amt                      0.0869      0.033      2.644      0.008       0.022       0.151\n",
       "Msa_Dma_encoded                  0.2063      0.031      6.702      0.000       0.146       0.267\n",
       "Salesperson_encoded             -0.0292      0.029     -0.995      0.320      -0.087       0.028\n",
       "ST_encoded                       0.0867      0.030      2.870      0.004       0.028       0.146\n",
       "Chain_Name_encoded               0.0881      0.030      2.892      0.004       0.028       0.148\n",
       "LMS_Available_Matching_Funds     0.1738      0.033      5.237      0.000       0.109       0.239\n",
       "================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelXR = sm.Logit(y, XR)\n",
    "resultXR = modelXR.fit()\n",
    "resultXR.summary ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF DC_Name_encoded: 1.0262136278368992\n",
      "VIF Tot_Sls_Amt: 1.0020736689195004\n",
      "VIF Msa_Dma_encoded: 1.1135314052548284\n",
      "VIF Salesperson_encoded: 1.0208424366289444\n",
      "VIF ST_encoded: 1.0749734543219744\n",
      "VIF Chain_Name_encoded: 1.1052465134450666\n",
      "VIF LMS_Available_Matching_Funds: 1.0128101156911191\n"
     ]
    }
   ],
   "source": [
    "for i, col in enumerate(XR.columns):            # check VIF\n",
    "    print('VIF {}: {}'.format(col,variance_inflation_factor(XR.values,i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XR2 = X[['DC_Name_encoded','Auto_Ship_Ind', 'Msa_Dma_encoded',\n",
    "                'SCS_Program', 'Specialty_Solutions','MRA_Program_Type_-_Active_AH_encoded',\n",
    "                'Region_encoded','LMS_Available_Matching_Funds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XR2_train = X_train[['DC_Name_encoded','Auto_Ship_Ind', 'Msa_Dma_encoded',\n",
    "                'SCS_Program', 'Specialty_Solutions','MRA_Program_Type_-_Active_AH_encoded',\n",
    "                'Region_encoded','LMS_Available_Matching_Funds']]\n",
    "\n",
    "XR2_test = X_test[['DC_Name_encoded','Auto_Ship_Ind', 'Msa_Dma_encoded',\n",
    "                'SCS_Program', 'Specialty_Solutions','MRA_Program_Type_-_Active_AH_encoded',\n",
    "                'Region_encoded','LMS_Available_Matching_Funds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.669327\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>340B_Active</td>   <th>  No. Observations:  </th>  <td>  4846</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  4838</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Wed, 28 Mar 2018</td> <th>  Pseudo R-squ.:     </th>  <td>-0.4504</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>11:03:04</td>     <th>  Log-Likelihood:    </th> <td> -3243.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -2236.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>  <td> 1.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                    <td></td>                      <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DC_Name_encoded</th>                      <td>    0.0995</td> <td>    0.030</td> <td>    3.362</td> <td> 0.001</td> <td>    0.041</td> <td>    0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Auto_Ship_Ind</th>                        <td>    0.0941</td> <td>    0.030</td> <td>    3.144</td> <td> 0.002</td> <td>    0.035</td> <td>    0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Msa_Dma_encoded</th>                      <td>    0.3055</td> <td>    0.036</td> <td>    8.532</td> <td> 0.000</td> <td>    0.235</td> <td>    0.376</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SCS_Program</th>                          <td>    0.1433</td> <td>    0.031</td> <td>    4.600</td> <td> 0.000</td> <td>    0.082</td> <td>    0.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Specialty_Solutions</th>                  <td>   -0.1190</td> <td>    0.031</td> <td>   -3.843</td> <td> 0.000</td> <td>   -0.180</td> <td>   -0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MRA_Program_Type_-_Active_AH_encoded</th> <td>   -0.1495</td> <td>    0.031</td> <td>   -4.777</td> <td> 0.000</td> <td>   -0.211</td> <td>   -0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Region_encoded</th>                       <td>   -0.1970</td> <td>    0.037</td> <td>   -5.395</td> <td> 0.000</td> <td>   -0.269</td> <td>   -0.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LMS_Available_Matching_Funds</th>         <td>    0.1276</td> <td>    0.033</td> <td>    3.834</td> <td> 0.000</td> <td>    0.062</td> <td>    0.193</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:            340B_Active   No. Observations:                 4846\n",
       "Model:                          Logit   Df Residuals:                     4838\n",
       "Method:                           MLE   Df Model:                            7\n",
       "Date:                Wed, 28 Mar 2018   Pseudo R-squ.:                 -0.4504\n",
       "Time:                        11:03:04   Log-Likelihood:                -3243.6\n",
       "converged:                       True   LL-Null:                       -2236.3\n",
       "                                        LLR p-value:                     1.000\n",
       "========================================================================================================\n",
       "                                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------------------\n",
       "DC_Name_encoded                          0.0995      0.030      3.362      0.001       0.041       0.157\n",
       "Auto_Ship_Ind                            0.0941      0.030      3.144      0.002       0.035       0.153\n",
       "Msa_Dma_encoded                          0.3055      0.036      8.532      0.000       0.235       0.376\n",
       "SCS_Program                              0.1433      0.031      4.600      0.000       0.082       0.204\n",
       "Specialty_Solutions                     -0.1190      0.031     -3.843      0.000      -0.180      -0.058\n",
       "MRA_Program_Type_-_Active_AH_encoded    -0.1495      0.031     -4.777      0.000      -0.211      -0.088\n",
       "Region_encoded                          -0.1970      0.037     -5.395      0.000      -0.269      -0.125\n",
       "LMS_Available_Matching_Funds             0.1276      0.033      3.834      0.000       0.062       0.193\n",
       "========================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelXR2 = sm.Logit(y, XR2)\n",
    "resultXR2 = modelXR2.fit()\n",
    "resultXR2.summary ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch to optimize the model, using the reduced feature set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we optimized the model that seems to perform the best?   We try many parameters via GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for defining a tree:\n",
    "\n",
    "1.min_samples_split ◦Defines the minimum number of samples (or observations) which are required in a node to be considered for splitting.\n",
    "◦Used to control over-fitting. Higher values prevent a model from learning relations which might be highly specific to the particular sample selected for a tree.\n",
    "◦Too high values can lead to under-fitting hence, it should be tuned using CV.\n",
    "\n",
    "2.min_samples_leaf ◦Defines the minimum samples (or observations) required in a terminal node or leaf.\n",
    "◦Used to control over-fitting similar to min_samples_split.\n",
    "◦Generally lower values should be chosen for imbalanced class problems because the regions in which the minority class will be in majority will be very small.\n",
    "\n",
    "3.min_weight_fraction_leaf ◦Similar to min_samples_leaf but defined as a fraction of the total number of observations instead of an integer.\n",
    "◦Only one of #2 and #3 should be defined.\n",
    "\n",
    "4.max_depth ◦The maximum depth of a tree.\n",
    "◦Used to control over-fitting as higher depth will allow model to learn relations very specific to a particular sample.\n",
    "◦Should be tuned using CV.\n",
    "\n",
    "5.max_leaf_nodes ◦The maximum number of terminal nodes or leaves in a tree.\n",
    "◦Can be defined in place of max_depth. Since binary trees are created, a depth of ‘n’ would produce a maximum of 2^n leaves.\n",
    "◦If this is defined, GBM will ignore max_depth.\n",
    "\n",
    "6.max_features ◦The number of features to consider while searching for a best split. These will be randomly selected.\n",
    "◦As a thumb-rule, square root of the total number of features works great but we should check upto 30-40% of the total number of features.\n",
    "◦Higher values can lead to over-fitting but depends on case to case.\n",
    "\n",
    "Parameters for managing boosting:\n",
    "    \n",
    "1.learning_rate ◦This determines the impact of each tree on the final outcome (step 2.4). GBM works by starting with an initial estimate which is updated using the output of each tree. The learning parameter controls the magnitude of this change in the estimates.\n",
    "◦Lower values are generally preferred as they make the model robust to the specific characteristics of tree and thus allowing it to generalize well.\n",
    "◦Lower values would require higher number of trees to model all the relations and will be computationally expensive.\n",
    "\n",
    "2.n_estimators ◦The number of sequential trees to be modeled (step 2)\n",
    "◦Though GBM is fairly robust at higher number of trees but it can still overfit at a point. Hence, this should be tuned using CV for a particular learning rate.\n",
    "\n",
    "3.subsample ◦The fraction of observations to be selected for each tree. Selection is done by random sampling.\n",
    "◦Values slightly less than 1 make the model robust by reducing the variance.\n",
    "◦Typical values ~0.8 generally work fine but can be fine-tuned further.\n",
    "\n",
    "\n",
    "Miscellaneous parameters:\n",
    "    \n",
    "1.loss ◦It refers to the loss function to be minimized in each split.\n",
    "◦It can have various values for classification and regression case. Generally the default values work fine. Other values should be chosen only if you understand their impact on the model.\n",
    "\n",
    "2.init ◦This affects initialization of the output.\n",
    "◦This can be used if we have made another model whose outcome is to be used as the initial estimates for GBM.\n",
    "\n",
    "3.random_state ◦The random number seed so that same random numbers are generated every time.\n",
    "◦This is important for parameter tuning. If we don’t fix the random number, then we’ll have different outcomes for subsequent runs on the same parameters and it becomes difficult to compare models.\n",
    "◦It can potentially result in overfitting to a particular random sample selected. We can try running models for different random samples, which is computationally expensive and generally not used.\n",
    "\n",
    "4.verbose ◦The type of output to be printed when the model fits. The different values can be: ◾0: no output generated (default)\n",
    "◾1: output generated for trees in certain intervals\n",
    "◾>1: output generated for all trees\n",
    "\n",
    "\n",
    "5.warm_start ◦This parameter has an interesting application and can help a lot if used judicially.\n",
    "◦Using this, we can fit additional trees on previous fits of a model. It can save a lot of time and you should explore this option for advanced applications\n",
    "\n",
    "6.presort  ◦ Select whether to presort data for faster splits.\n",
    "◦It makes the selection automatically by default but it can be changed if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbr_params = dict(learning_rate=np.arange(0.1, 0.5, 0.1),\n",
    "                        min_samples_split=np.arange(5,7,1),\n",
    "                        min_samples_leaf=np.arange(3,6,1),\n",
    "                        max_depth=np.arange(2, 5, 1),\n",
    "                        max_features=np.array([1, 2, 3, 4, 5, 6, 7, None, 'auto', 'sqrt', 'log2']),\n",
    "                        n_estimators=np.arange(60, 100, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_gbr = GridSearchCV(estimator=GradientBoostingClassifier(), param_grid=gbr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'learning_rate': array([ 0.1,  0.2,  0.3,  0.4]), 'min_samples_split': array([5, 6]), 'min_samples_leaf': array([3, 4, 5]), 'max_depth': array([2, 3, 4]), 'max_features': array([1, 2, 3, 4, 5, 6, 7, None, 'auto', 'sqrt', 'log2'], dtype=object), 'n_estimators': array([60, 80])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_gbr.fit(XR_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.20000000000000001,\n",
       " 'max_depth': 4,\n",
       " 'max_features': 7,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 80}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_gbr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84072704867529269"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_gbr.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.20000000000000001, loss='deviance',\n",
       "              max_depth=4, max_features=7, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=3, min_samples_split=5,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=80,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_gbr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbest_model = GradientBoostingClassifier(criterion='friedman_mse', init=None,\\n              learning_rate=0.40000000000000002, loss='deviance',\\n              max_depth=3, max_features='log2', max_leaf_nodes=None,\\n              min_impurity_decrease=0.0, min_impurity_split=None,\\n              min_samples_leaf=1, min_samples_split=3,\\n              min_weight_fraction_leaf=0.0, n_estimators=70,\\n              presort='auto', random_state=None, subsample=1.0, verbose=0,\\n              warm_start=False)\\nbest_model.fit(XR_train, y_train)\\n\\n\""
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### This is the original GridSearch settings - orig Model\n",
    "\"\"\"\n",
    "best_model = GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
    "              learning_rate=0.40000000000000002, loss='deviance',\n",
    "              max_depth=3, max_features='log2', max_leaf_nodes=None,\n",
    "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "              min_samples_leaf=1, min_samples_split=3,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=70,\n",
    "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
    "              warm_start=False)\n",
    "best_model.fit(XR_train, y_train)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.2, loss='deviance', max_depth=4,\n",
       "              max_features=7, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=3, min_samples_split=5,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=80,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This is GridSearch with updated settings - Model 2\n",
    "\n",
    "best_model2 = GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
    "              learning_rate=0.20000000000000001, loss='deviance',\n",
    "              max_depth=4, max_features=7, max_leaf_nodes=None,\n",
    "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "              min_samples_leaf=3, min_samples_split=5,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=80,\n",
    "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
    "              warm_start=False)\n",
    "best_model2.fit(XR_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score cross-validated:  0.834250393256\n",
      "Recall Score:  0.833125\n",
      "Precision Score average:   0.263232526882\n"
     ]
    }
   ],
   "source": [
    "best_model2.feature_importances_\n",
    "pred_best_model2 = best_model2.predict(XR_test) \n",
    "best_model2_score_acc = np.mean(cross_val_score(best_model2, XR_train, y_train, cv=5))\n",
    "best_model2_score_recall = recall_score(y_test, pred_best_model2, average='weighted')\n",
    "best_model2_score_avgprecision = average_precision_score(y_test, pred_best_model2)\n",
    "\n",
    "print(\"Accuracy Score cross-validated: \", best_model2_score_acc)\n",
    "print(\"Recall Score: \", best_model2_score_recall)\n",
    "print(\"Precision Score average:  \", best_model2_score_avgprecision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Decision Tree Grid Search (Model 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtr_params = dict(min_samples_split=np.arange(5,7,1),\n",
    "                        min_samples_leaf=np.arange(3,6,1),\n",
    "                        max_depth=np.arange(2, 5, 1),\n",
    "                        max_features=np.array([1, 2, 3, 4, 5, 6, 7, None, 'auto', 'sqrt', 'log2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_dtr = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=dtr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'min_samples_split': array([5, 6]), 'min_samples_leaf': array([3, 4, 5]), 'max_depth': array([2, 3, 4]), 'max_features': array([1, 2, 3, 4, 5, 6, 7, None, 'auto', 'sqrt', 'log2'], dtype=object)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_dtr.fit(XR_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4,\n",
       " 'max_features': 7,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 5}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_dtr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83210104744300672"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_dtr.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
       "            max_features=7, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=3,\n",
       "            min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_dtr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
       "            max_features=7, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=3,\n",
       "            min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model3 = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=7, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "            min_impurity_split=None, min_samples_leaf=3,\n",
    "            min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=None, splitter='best')\n",
    "best_model3.fit(XR_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score cross-validated:  0.82192988702\n",
      "Recall Score:  0.82625\n",
      "Precision Score average:   0.183509787703\n"
     ]
    }
   ],
   "source": [
    "best_model3.feature_importances_\n",
    "pred_best_model3 = best_model3.predict(XR_test) \n",
    "best_model3_score_acc = np.mean(cross_val_score(best_model3, XR_train, y_train, cv=5))\n",
    "best_model3_score_recall = recall_score(y_test, pred_best_model3, average='weighted')\n",
    "best_model3_score_avgprecision = average_precision_score(y_test, pred_best_model3)\n",
    "\n",
    "print(\"Accuracy Score cross-validated: \", best_model3_score_acc)\n",
    "print(\"Recall Score: \", best_model3_score_recall)\n",
    "print(\"Precision Score average:  \", best_model3_score_avgprecision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model (reduced feature set) on ALL observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We trained and fitted the model with a reduced set of observations (to address the class imbalance for the label), so now we want to try the model on all observations, to learn which pharmacies it predicts as contract pharmacies for Macro Helix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XR_all_obs = X[['DC_Name_encoded', 'Tot_Sls_Amt', 'Msa_Dma_encoded',\n",
    "                'Salesperson_encoded', 'ST_encoded',\n",
    "                'Chain_Name_encoded','LMS_Available_Matching_Funds']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_best_model2_all_obs = best_model2.predict(XR_all_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score cross-validated:  0.178312640303\n",
      "Recall Score:  0.88196450681\n",
      "Recall Score - nt weighted:  0.410225921522\n",
      "Precision Score average:   0.438523341441\n"
     ]
    }
   ],
   "source": [
    "best_model2_all_obs_score_acc = np.mean(cross_val_score(best_model2, XR_all_obs, y, cv=5))\n",
    "best_model2_all_obs_score_recall = recall_score(y, pred_best_model2_all_obs, average='weighted')\n",
    "best_model2_all_obs_score_recall_nw = recall_score(y, pred_best_model2_all_obs) \n",
    "best_model2_all_obs_score_avgprecision = average_precision_score(y, pred_best_model2_all_obs)\n",
    "\n",
    "print(\"Accuracy Score cross-validated: \", best_model2_all_obs_score_acc)\n",
    "print(\"Recall Score: \", best_model2_all_obs_score_recall)\n",
    "print(\"Recall Score - nt weighted: \", best_model2_all_obs_score_recall_nw)\n",
    "print(\"Precision Score average:  \", best_model2_all_obs_score_avgprecision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall score is improved and is GREAT!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put Actual 340B and Predicted 340B into final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_clean['Actual_340B'] = df_clean['340B_Active'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = pred_best_model2_all_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 4425]\n",
      " [   1  421]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(q, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_clean['Predicted_340B'] = pred_best_model2_all_obs           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zip</th>\n",
       "      <th>Hm_Start_Dt</th>\n",
       "      <th>Channel_Type_Cd</th>\n",
       "      <th>Auto_Ship_Ind</th>\n",
       "      <th>Internal_Decor</th>\n",
       "      <th>Interior_Decor_Signage_Available_Funds</th>\n",
       "      <th>LMS_Enrolled</th>\n",
       "      <th>LMS_Available_Matching_Funds</th>\n",
       "      <th>LMS_Used_Funds_Most_Recent_3_Months</th>\n",
       "      <th>LMS_Used_Funds_Previous_3_Months</th>\n",
       "      <th>...</th>\n",
       "      <th>Salesperson_encoded</th>\n",
       "      <th>AH_Program_encoded</th>\n",
       "      <th>OTC_Front-end_Size_encoded</th>\n",
       "      <th>MRA_Program_Type_-_Active_AH_encoded</th>\n",
       "      <th>Msa_Dma_encoded</th>\n",
       "      <th>Signage_Program_encoded</th>\n",
       "      <th>3rd_Party_Vendor_encoded</th>\n",
       "      <th>Hospital_Associated_encoded</th>\n",
       "      <th>Actual_340B</th>\n",
       "      <th>Predicted_340B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Account</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10491</th>\n",
       "      <td>97463</td>\n",
       "      <td>732524</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1724.0</td>\n",
       "      <td>1</td>\n",
       "      <td>822.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17475</th>\n",
       "      <td>97630</td>\n",
       "      <td>732687</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19901</th>\n",
       "      <td>97471</td>\n",
       "      <td>732616</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309745</th>\n",
       "      <td>97467</td>\n",
       "      <td>735998</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652229</th>\n",
       "      <td>97370</td>\n",
       "      <td>734702</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>340.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Zip  Hm_Start_Dt  Channel_Type_Cd  Auto_Ship_Ind  Internal_Decor  \\\n",
       "Account                                                                       \n",
       "10491    97463       732524               30              1               1   \n",
       "17475    97630       732687               30              1               1   \n",
       "19901    97471       732616               30              0               1   \n",
       "309745   97467       735998               30              0               0   \n",
       "652229   97370       734702               30              0               1   \n",
       "\n",
       "         Interior_Decor_Signage_Available_Funds  LMS_Enrolled  \\\n",
       "Account                                                         \n",
       "10491                                    1724.0             1   \n",
       "17475                                       0.0             1   \n",
       "19901                                       0.0             1   \n",
       "309745                                   2500.0             1   \n",
       "652229                                      0.0             1   \n",
       "\n",
       "         LMS_Available_Matching_Funds  LMS_Used_Funds_Most_Recent_3_Months  \\\n",
       "Account                                                                      \n",
       "10491                           822.0                                    1   \n",
       "17475                             0.0                                    1   \n",
       "19901                             0.0                                    1   \n",
       "309745                            0.0                                    0   \n",
       "652229                          340.0                                    1   \n",
       "\n",
       "         LMS_Used_Funds_Previous_3_Months       ...        \\\n",
       "Account                                         ...         \n",
       "10491                                   1       ...         \n",
       "17475                                   1       ...         \n",
       "19901                                   1       ...         \n",
       "309745                                  0       ...         \n",
       "652229                                  0       ...         \n",
       "\n",
       "         Salesperson_encoded  AH_Program_encoded  OTC_Front-end_Size_encoded  \\\n",
       "Account                                                                        \n",
       "10491                      1                   4                           1   \n",
       "17475                      1                   0                           3   \n",
       "19901                      1                   0                           4   \n",
       "309745                     1                   0                           1   \n",
       "652229                     1                   0                           0   \n",
       "\n",
       "         MRA_Program_Type_-_Active_AH_encoded  Msa_Dma_encoded  \\\n",
       "Account                                                          \n",
       "10491                                       7              183   \n",
       "17475                                       3              190   \n",
       "19901                                       2              183   \n",
       "309745                                      8              183   \n",
       "652229                                      8              183   \n",
       "\n",
       "         Signage_Program_encoded  3rd_Party_Vendor_encoded  \\\n",
       "Account                                                      \n",
       "10491                          0                        18   \n",
       "17475                          0                        18   \n",
       "19901                          0                        18   \n",
       "309745                         3                        18   \n",
       "652229                         0                        18   \n",
       "\n",
       "         Hospital_Associated_encoded  Actual_340B  Predicted_340B  \n",
       "Account                                                            \n",
       "10491                             15            0               0  \n",
       "17475                             15            0               0  \n",
       "19901                             15            0               0  \n",
       "309745                            15            0               0  \n",
       "652229                            15            0               0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to file for the business to review predicted contract pharmacies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_clean.to_csv('data/340B_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(df_clean[df_clean['Predicted_340B']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_clean['Predicted_340B'].unique()\n",
    "df_clean['Predicted_340B'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XR_all_obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
